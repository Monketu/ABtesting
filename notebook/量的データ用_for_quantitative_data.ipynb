{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 量的データ用（For quantitaive data）\n",
    "[Methods]  \n",
    "- Clustering methods : Kmeans, GMM, FSSEM, FSS-Kmeans    \n",
    "- Allocation methods : random, proportional allocation, post stratification, optimal allocation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 実験設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = 2  # クラスタ数\n",
    "n_features_to_select = 17  # 選択される最大の特徴量数\n",
    "\n",
    "N_SAMPLES = 100  # 標本サイズ\n",
    "H = clusters\n",
    "N_TRIALS = 1000  # 試行回数（標本平均を求める回数）\n",
    "N_EXPERIMENT = 10  # 分散を求める回数\n",
    "m_VALUE = 2  # 各クラスタの最小標本数(最適標本配分)\n",
    "RANDOM_STATE = 0  # 乱数シード\n",
    "CRITERION_LIST = [\"ml\", \"tr\", \"none\"]\n",
    "CLUSTERING_METHOD_LIST = [\"gmm\", \"kmeans\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------\n",
    "### ライブラリのインポート＆その他の設定（Importing Libraries & Other Settings）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 8\n"
     ]
    }
   ],
   "source": [
    "# 基本的なライブラリ\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy.typing import NDArray\n",
    "from scipy import stats\n",
    "\n",
    "# Scikit-learn関連\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.utils.validation import check_X_y\n",
    "\n",
    "# 抽象基底クラス (ABC)\n",
    "from abc import ABCMeta, abstractmethod\n",
    "\n",
    "# タイピングのサポート\n",
    "from typing import Optional\n",
    "\n",
    "# シード設定\n",
    "from lightning.pytorch import seed_everything\n",
    "\n",
    "seed_everything(8)\n",
    "\n",
    "# 可視化の設定\n",
    "import matplotlib.pyplot as plt\n",
    "import japanize_matplotlib\n",
    "\n",
    "plt.style.use(\"ggplot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------\n",
    "### データの前処理（Data Preprocessing）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 外れ値を除去する関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 外れ値の除去\n",
    "def remove_outliers_zscore(\n",
    "    data: pd.DataFrame, metric: str, threshold: float = 2\n",
    ") -> pd.DataFrame:\n",
    "    z_scores = np.abs(stats.zscore(data[metric]))\n",
    "    data = data[(z_scores < threshold)]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### メルカリデータ（df1：全部, df2：一部）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df1(all the data)\n",
    "df1 = pd.read_csv(\n",
    "    R\"C:\\Users\\HaruMomozu\\Documents\\aug_first_cpn_data_for_ab_test_sensibility_tsukuba.csv\"\n",
    ")\n",
    "obj1 = \"GMV\"\n",
    "features_list1 = [\n",
    "    \"hist_4_day_buy_num\",\n",
    "    \"hist_4_day_gmv\",\n",
    "    \"his_4_day_is_buy\",\n",
    "    \"hist_30_day_buy_days\",\n",
    "    \"hist_30_day_buy_num\",\n",
    "    \"hist_30_day_gmv\",\n",
    "    \"hist_30_day_buy_recency\",\n",
    "    \"hist_30_day_pay_days\",\n",
    "    \"hist_30_day_atpu\",\n",
    "    \"hist_30_day_gpv\",\n",
    "    \"hist_30_day_pay_recency\",\n",
    "    \"hist_30_day_list_days\",\n",
    "    \"hist_30_day_list_num\",\n",
    "    \"hist_30_day_list_recency\",\n",
    "    \"hist_30_day_like_count\",\n",
    "    \"hist_30_day_like_count_not_deleted\",\n",
    "    \"hist_30_day_like_recency\",\n",
    "]\n",
    "\n",
    "# df2(subset of the data)\n",
    "df2 = df1.iloc[:3000]\n",
    "obj2 = obj1\n",
    "features_list2 = features_list1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 外れ値除去と標準化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df2  # choose from (df1, df2)\n",
    "obj = obj2  # choose from (obj1, obj2)\n",
    "features_list = features_list2  # choose from (features_list1, features_list2)\n",
    "\n",
    "# 外れ値除去\n",
    "df = remove_outliers_zscore(df, obj)\n",
    "\n",
    "# 標準化\n",
    "X = df[features_list]\n",
    "scaler = StandardScaler()\n",
    "scaled_features = scaler.fit_transform(X)\n",
    "X_scaled = pd.DataFrame(scaled_features, columns=features_list)\n",
    "\n",
    "# 目的変数\n",
    "y = df[obj]\n",
    "\n",
    "# 行を詰める\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------\n",
    "### Wrapper法でクラスタリング"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Wrapper Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Wrapper(BaseEstimator, TransformerMixin):\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_features_to_select: int,\n",
    "        n_clusters: int,\n",
    "        criterion: str = \"ml\",\n",
    "        clustering_method: str = \"gmm\",\n",
    "        random_state: int = 0,\n",
    "    ):\n",
    "        self.n_features_to_select = n_features_to_select  # 特徴量数\n",
    "        self.n_clusters = n_clusters  # クラスタ数\n",
    "        self.criterion = criterion  # 特徴量選択基準\n",
    "        self.clustering_method = clustering_method  # クラスタリング手法\n",
    "        self.random_state = random_state\n",
    "\n",
    "    def fss(self, X: pd.DataFrame, y: pd.DataFrame) -> \"Wrapper\":\n",
    "        X, y = check_X_y(X, y)\n",
    "\n",
    "        n_features = X.shape[1]  # 総特徴量数\n",
    "        self.selected_features_ = []  # ここに選択した特徴量を入れる\n",
    "\n",
    "        # 選ばれた特徴量と残っている特徴量の初期化\n",
    "        current_features = []\n",
    "        remaining_features = list(range(n_features))\n",
    "        # best_score = -np.inf ###############################ここもどす\n",
    "\n",
    "        while len(current_features) < self.n_features_to_select:\n",
    "            best_score = -np.inf  ################################ここ消す\n",
    "            best_feature = None  # 選ぶ特徴量の初期化\n",
    "\n",
    "            for feature in remaining_features:\n",
    "                temp_features = tuple(\n",
    "                    current_features + [feature]\n",
    "                )  # 特徴量をひとつ加え、score計算\n",
    "                score = self.crit(X[:, temp_features])\n",
    "                if score > best_score:\n",
    "                    best_score = score\n",
    "                    best_feature = feature\n",
    "\n",
    "            if best_feature is not None:\n",
    "                current_features.append(\n",
    "                    best_feature\n",
    "                )  # best feature をcurrent features に追加\n",
    "                print(\"current_features:\", current_features)\n",
    "                print(\"score for current_features:\", self.crit(X[:, current_features]))\n",
    "                remaining_features.remove(\n",
    "                    best_feature\n",
    "                )  # best feature をremaining features から取り除く\n",
    "                self.selected_features_ = current_features\n",
    "            else:\n",
    "                break\n",
    "\n",
    "        print(\"score using all features:\", self.crit(X[:, :]))\n",
    "        print(\"\")\n",
    "        # 選ばれた特徴量サブセットでクラスタリング\n",
    "        final_features = X[:, self.selected_features_]\n",
    "        if self.clustering_method == \"gmm\":\n",
    "            self.final_model_ = GaussianMixture(\n",
    "                n_components=self.n_clusters,\n",
    "                random_state=self.random_state,\n",
    "                init_params=\"kmeans\",\n",
    "            )\n",
    "        elif self.clustering_method == \"kmeans\":\n",
    "            self.final_model_ = KMeans(\n",
    "                n_clusters=self.n_clusters, random_state=self.random_state\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown clustering method: {self.clustering_method}\")\n",
    "\n",
    "        self.final_model_.fit(final_features)\n",
    "        self.final_cluster_assignments_ = self.final_model_.predict(final_features)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def crit(self, X: pd.DataFrame) -> float:\n",
    "        # クラスタリング手法がGMMの場合\n",
    "        if self.clustering_method == \"gmm\":\n",
    "            em = GaussianMixture(\n",
    "                n_components=self.n_clusters,\n",
    "                random_state=self.random_state,\n",
    "                init_params=\"kmeans\",\n",
    "            )\n",
    "            em.fit(X)\n",
    "            labels = em.predict(X)\n",
    "\n",
    "            if self.criterion == \"tr\":\n",
    "                means = em.means_  # 平均ベクトル\n",
    "                covariances = (\n",
    "                    em.covariances_ + 1e-7\n",
    "                )  # 共分散行列(各要素に微小な数が加算される)\n",
    "                weights = em.weights_  # 混合比率\n",
    "                overall_mean = np.sum(\n",
    "                    weights[:, np.newaxis] * means, axis=0\n",
    "                )  # 標本平均 #np.newaxisを使って1次元配列から2次元配列にする\n",
    "\n",
    "                S_W = np.sum(weights[:, np.newaxis, np.newaxis] * covariances, axis=0)\n",
    "                S_B = np.sum(\n",
    "                    weights[:, np.newaxis, np.newaxis]\n",
    "                    * np.einsum(\n",
    "                        \"...i,...j->...ij\", means - overall_mean, means - overall_mean\n",
    "                    ),\n",
    "                    axis=0,\n",
    "                )\n",
    "                score = np.trace(np.linalg.solve(S_W, S_B))\n",
    "\n",
    "            elif self.criterion == \"ml\":\n",
    "                score = em.score(X)\n",
    "\n",
    "        # クラスタリング手法がKMEANSの場合\n",
    "        if self.clustering_method == \"kmeans\":\n",
    "            kmeans = KMeans(\n",
    "                n_clusters=self.n_clusters,\n",
    "                random_state=self.random_state,\n",
    "            )\n",
    "            kmeans.fit(X)\n",
    "            labels = kmeans.predict(X)\n",
    "\n",
    "            if self.criterion == \"tr\":\n",
    "                labels = kmeans.labels_\n",
    "                cluster_centers = kmeans.cluster_centers_\n",
    "\n",
    "                sw_i_list = []\n",
    "                for i in range(self.n_clusters):\n",
    "                    cluster_points = X[labels == i]\n",
    "\n",
    "                    if cluster_points.shape[0] <= 2:\n",
    "                        # データポイントが1つの場合はゼロ行列を使用\n",
    "                        sw_i = np.zeros((X.shape[1], X.shape[1])) + 1e-7\n",
    "                    else:\n",
    "                        sw_i = (np.cov(cluster_points, rowvar=False) + 1e-7) * np.sum(\n",
    "                            labels\n",
    "                            == i  # データ数を重みに使う代わりにデータの割合を使う\n",
    "                        )\n",
    "                        if np.isscalar(sw_i):  # スカラー値のとき\n",
    "                            sw_i = np.array([[sw_i]])\n",
    "                    sw_i_list.append(sw_i)\n",
    "\n",
    "                # 全クラスターの S_W を合計\n",
    "                S_W = np.sum(sw_i_list, axis=0)\n",
    "\n",
    "                # クラスター間散布行列 S_B を計算\n",
    "                overall_mean = np.mean(X, axis=0)\n",
    "                S_B = sum(\n",
    "                    (np.sum(labels == i) / X.shape[0])  # 割合にする\n",
    "                    * np.outer(\n",
    "                        cluster_centers[i] - overall_mean,\n",
    "                        cluster_centers[i] - overall_mean,\n",
    "                    )\n",
    "                    # *(cluster_centers[i] - overall_mean) @ (cluster_centers[i] - overall_mean).T\n",
    "                    for i in range(self.n_clusters)\n",
    "                )\n",
    "\n",
    "                # 散乱分離性を計算\n",
    "                score = np.trace(np.linalg.solve(S_W, S_B))\n",
    "\n",
    "            elif self.criterion == \"ml\":\n",
    "                score = -kmeans.score(X)\n",
    "\n",
    "        return score\n",
    "\n",
    "    def get_feature_index_out(self) -> NDArray:\n",
    "        return np.array(self.selected_features_)  # 選択された特徴量のインデックス\n",
    "\n",
    "    def get_final_cluster_assignments(self) -> NDArray:\n",
    "        return self.final_cluster_assignments_  # 最終的なクラスタリング結果"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Wrapper classでクラスタリングしたとき"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HaruMomozu\\Desktop\\momozu\\ABtesting\\.venv\\Lib\\site-packages\\threadpoolctl.py:1214: RuntimeWarning: \n",
      "Found Intel OpenMP ('libiomp') and LLVM OpenMP ('libomp') loaded at\n",
      "the same time. Both libraries are known to be incompatible and this\n",
      "can cause random crashes or deadlocks on Linux when loaded in the\n",
      "same Python program.\n",
      "Using threadpoolctl may cause crashes or deadlocks. For more\n",
      "information and possible workarounds, please see\n",
      "    https://github.com/joblib/threadpoolctl/blob/master/multiple_openmp.md\n",
      "\n",
      "  warnings.warn(msg, RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_features: [2]\n",
      "score for current_features: 909090.9090908796\n",
      "current_features: [2, 6]\n",
      "score for current_features: 909092.696340563\n",
      "current_features: [2, 6, 0]\n",
      "score for current_features: 909092.9174129287\n",
      "current_features: [2, 6, 0, 4]\n",
      "score for current_features: 909093.03898363\n",
      "current_features: [2, 6, 0, 4, 13]\n",
      "score for current_features: 909093.0535786963\n",
      "current_features: [2, 6, 0, 4, 13, 11]\n",
      "score for current_features: 909093.0954386938\n",
      "current_features: [2, 6, 0, 4, 13, 11, 7]\n",
      "score for current_features: 909093.1068759939\n",
      "current_features: [2, 6, 0, 4, 13, 11, 7, 10]\n",
      "score for current_features: 909093.1522171405\n",
      "current_features: [2, 6, 0, 4, 13, 11, 7, 10, 3]\n",
      "score for current_features: 909093.1626630934\n",
      "current_features: [2, 6, 0, 4, 13, 11, 7, 10, 3, 16]\n",
      "score for current_features: 909093.1680781737\n",
      "current_features: [2, 6, 0, 4, 13, 11, 7, 10, 3, 16, 8]\n",
      "score for current_features: 909093.1746659708\n",
      "current_features: [2, 6, 0, 4, 13, 11, 7, 10, 3, 16, 8, 1]\n",
      "score for current_features: 909093.1757051758\n",
      "current_features: [2, 6, 0, 4, 13, 11, 7, 10, 3, 16, 8, 1, 5]\n",
      "score for current_features: 1432.8630638881216\n",
      "current_features: [2, 6, 0, 4, 13, 11, 7, 10, 3, 16, 8, 1, 5, 15]\n",
      "score for current_features: 51.66320099853475\n",
      "current_features: [2, 6, 0, 4, 13, 11, 7, 10, 3, 16, 8, 1, 5, 15, 9]\n",
      "score for current_features: 6.2158663652860495\n",
      "current_features: [2, 6, 0, 4, 13, 11, 7, 10, 3, 16, 8, 1, 5, 15, 9, 14]\n",
      "score for current_features: 4.138210858042983\n",
      "current_features: [2, 6, 0, 4, 13, 11, 7, 10, 3, 16, 8, 1, 5, 15, 9, 14, 12]\n",
      "score for current_features: 3.503392568502385\n",
      "score using all features: 3.503392568502377\n",
      "\n",
      "[ fssem_tr ]\n",
      "選択された特徴量のインデックス :  [ 2  6  0  4 13 11  7 10  3 16  8  1  5 15  9 14 12]\n",
      "選択された特徴量の数 :  17\n",
      "各層のクラスタサイズ :  [ 766 2194]\n",
      "\n",
      "current_features: [2]\n",
      "score for current_features: 5.296217738800851\n",
      "current_features: [2, 0]\n",
      "score for current_features: 7.412028182206607\n",
      "current_features: [2, 0, 1]\n",
      "score for current_features: 9.463516609311249\n",
      "current_features: [2, 0, 1, 6]\n",
      "score for current_features: 8.718061344668877\n",
      "current_features: [2, 0, 1, 6, 4]\n",
      "score for current_features: 7.67633877310335\n",
      "current_features: [2, 0, 1, 6, 4, 3]\n",
      "score for current_features: 7.323216322663467\n",
      "current_features: [2, 0, 1, 6, 4, 3, 14]\n",
      "score for current_features: 6.105876622711637\n",
      "current_features: [2, 0, 1, 6, 4, 3, 14, 16]\n",
      "score for current_features: 4.912534172871875\n",
      "current_features: [2, 0, 1, 6, 4, 3, 14, 16, 11]\n",
      "score for current_features: 3.545694725940698\n",
      "current_features: [2, 0, 1, 6, 4, 3, 14, 16, 11, 13]\n",
      "score for current_features: 2.4561914347826046\n",
      "current_features: [2, 0, 1, 6, 4, 3, 14, 16, 11, 13, 10]\n",
      "score for current_features: 1.1026742544935273\n",
      "current_features: [2, 0, 1, 6, 4, 3, 14, 16, 11, 13, 10, 7]\n",
      "score for current_features: 0.05803649836623397\n",
      "current_features: [2, 0, 1, 6, 4, 3, 14, 16, 11, 13, 10, 7, 12]\n",
      "score for current_features: -0.5373053215274461\n",
      "current_features: [2, 0, 1, 6, 4, 3, 14, 16, 11, 13, 10, 7, 12, 9]\n",
      "score for current_features: 1.7009425021529643\n",
      "current_features: [2, 0, 1, 6, 4, 3, 14, 16, 11, 13, 10, 7, 12, 9, 8]\n",
      "score for current_features: 5.832326161798033\n",
      "current_features: [2, 0, 1, 6, 4, 3, 14, 16, 11, 13, 10, 7, 12, 9, 8, 5]\n",
      "score for current_features: 4.948589129959406\n",
      "current_features: [2, 0, 1, 6, 4, 3, 14, 16, 11, 13, 10, 7, 12, 9, 8, 5, 15]\n",
      "score for current_features: 3.877281662219387\n",
      "score using all features: 3.8772816622193904\n",
      "\n",
      "[ fssem_ml ]\n",
      "選択された特徴量のインデックス :  [ 2  0  1  6  4  3 14 16 11 13 10  7 12  9  8  5 15]\n",
      "選択された特徴量の数 :  17\n",
      "各層のクラスタサイズ :  [ 766 2194]\n",
      "\n",
      "current_features: [2]\n",
      "score for current_features: 3378.378378378378\n",
      "current_features: [2, 6]\n",
      "score for current_features: 3378.3809381725887\n",
      "current_features: [2, 6, 14]\n",
      "score for current_features: 3378.3814983547595\n",
      "current_features: [2, 6, 14, 13]\n",
      "score for current_features: 3378.3819362403387\n",
      "current_features: [2, 6, 14, 13, 7]\n",
      "score for current_features: 3378.382472734431\n",
      "current_features: [2, 6, 14, 13, 7, 10]\n",
      "score for current_features: 3378.3842306898546\n",
      "current_features: [2, 6, 14, 13, 7, 10, 1]\n",
      "score for current_features: 3378.3844507271874\n",
      "current_features: [2, 6, 14, 13, 7, 10, 1, 8]\n",
      "score for current_features: 3378.3845829077663\n",
      "current_features: [2, 6, 14, 13, 7, 10, 1, 8, 9]\n",
      "score for current_features: 3378.384608534353\n",
      "current_features: [2, 6, 14, 13, 7, 10, 1, 8, 9, 5]\n",
      "score for current_features: 0.06058792935783921\n",
      "current_features: [2, 6, 14, 13, 7, 10, 1, 8, 9, 5, 0]\n",
      "score for current_features: 0.18003599769135345\n",
      "current_features: [2, 6, 14, 13, 7, 10, 1, 8, 9, 5, 0, 11]\n",
      "score for current_features: 0.10544585747662734\n",
      "current_features: [2, 6, 14, 13, 7, 10, 1, 8, 9, 5, 0, 11, 15]\n",
      "score for current_features: 0.0483425294070165\n",
      "current_features: [2, 6, 14, 13, 7, 10, 1, 8, 9, 5, 0, 11, 15, 12]\n",
      "score for current_features: 0.02504264500414388\n",
      "current_features: [2, 6, 14, 13, 7, 10, 1, 8, 9, 5, 0, 11, 15, 12, 4]\n",
      "score for current_features: 0.015144946461423564\n",
      "current_features: [2, 6, 14, 13, 7, 10, 1, 8, 9, 5, 0, 11, 15, 12, 4, 16]\n",
      "score for current_features: 0.000742208317867198\n",
      "current_features: [2, 6, 14, 13, 7, 10, 1, 8, 9, 5, 0, 11, 15, 12, 4, 16, 3]\n",
      "score for current_features: 0.0005941116649549262\n",
      "score using all features: 0.0005941116649549256\n",
      "\n",
      "[ fsskmeans_tr ]\n",
      "選択された特徴量のインデックス :  [ 2  6 14 13  7 10  1  8  9  5  0 11 15 12  4 16  3]\n",
      "選択された特徴量の数 :  17\n",
      "各層のクラスタサイズ :  [ 810 2150]\n",
      "\n",
      "current_features: [5]\n",
      "score for current_features: 1477.7781583611954\n",
      "current_features: [5, 14]\n",
      "score for current_features: 4602.21405197149\n",
      "current_features: [5, 14, 9]\n",
      "score for current_features: 6883.706313190895\n",
      "current_features: [5, 14, 9, 15]\n",
      "score for current_features: 9842.977906614366\n",
      "current_features: [5, 14, 9, 15, 7]\n",
      "score for current_features: 12839.03762205947\n",
      "current_features: [5, 14, 9, 15, 7, 12]\n",
      "score for current_features: 14761.66508035817\n",
      "current_features: [5, 14, 9, 15, 7, 12, 2]\n",
      "score for current_features: 17492.856256903135\n",
      "current_features: [5, 14, 9, 15, 7, 12, 2, 1]\n",
      "score for current_features: 20256.148609885375\n",
      "current_features: [5, 14, 9, 15, 7, 12, 2, 1, 10]\n",
      "score for current_features: 23115.595388616548\n",
      "current_features: [5, 14, 9, 15, 7, 12, 2, 1, 10, 16]\n",
      "score for current_features: 25689.555022354187\n",
      "current_features: [5, 14, 9, 15, 7, 12, 2, 1, 10, 16, 3]\n",
      "score for current_features: 27677.536674298783\n",
      "current_features: [5, 14, 9, 15, 7, 12, 2, 1, 10, 16, 3, 4]\n",
      "score for current_features: 30544.97909710727\n",
      "current_features: [5, 14, 9, 15, 7, 12, 2, 1, 10, 16, 3, 4, 13]\n",
      "score for current_features: 33222.379203191376\n",
      "current_features: [5, 14, 9, 15, 7, 12, 2, 1, 10, 16, 3, 4, 13, 8]\n",
      "score for current_features: 35139.7362547214\n",
      "current_features: [5, 14, 9, 15, 7, 12, 2, 1, 10, 16, 3, 4, 13, 8, 6]\n",
      "score for current_features: 37629.419436313874\n",
      "current_features: [5, 14, 9, 15, 7, 12, 2, 1, 10, 16, 3, 4, 13, 8, 6, 11]\n",
      "score for current_features: 40116.702423133764\n",
      "current_features: [5, 14, 9, 15, 7, 12, 2, 1, 10, 16, 3, 4, 13, 8, 6, 11, 0]\n",
      "score for current_features: 42411.14018616425\n",
      "score using all features: 42411.14018616425\n",
      "\n",
      "[ fsskmeans_ml ]\n",
      "選択された特徴量のインデックス :  [ 5 14  9 15  7 12  2  1 10 16  3  4 13  8  6 11  0]\n",
      "選択された特徴量の数 :  17\n",
      "各層のクラスタサイズ :  [ 810 2150]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Wrapper法を実装するための関数\n",
    "def process_wrapper(\n",
    "    name: str, instance: \"Wrapper\", X_scaled: pd.DataFrame, y: pd.DataFrame\n",
    "):\n",
    "    instance.fss(X_scaled, y)\n",
    "    selected_features_index = instance.get_feature_index_out()\n",
    "    cluster_label = instance.get_final_cluster_assignments()\n",
    "    cluster_size = np.unique(cluster_label, return_counts=True)[1]\n",
    "\n",
    "    return selected_features_index, cluster_label, cluster_size\n",
    "\n",
    "\n",
    "# Wrapperインスタンスのリスト\n",
    "instances = [\n",
    "    (\n",
    "        \"fssem_tr\",\n",
    "        Wrapper(\n",
    "            n_features_to_select=n_features_to_select,\n",
    "            n_clusters=clusters,\n",
    "            criterion=\"tr\",\n",
    "            clustering_method=\"gmm\",\n",
    "            random_state=0,\n",
    "        ),\n",
    "    ),\n",
    "    (\n",
    "        \"fssem_ml\",\n",
    "        Wrapper(\n",
    "            n_features_to_select=n_features_to_select,\n",
    "            n_clusters=clusters,\n",
    "            criterion=\"ml\",\n",
    "            clustering_method=\"gmm\",\n",
    "            random_state=0,\n",
    "        ),\n",
    "    ),\n",
    "    (\n",
    "        \"fsskmeans_tr\",\n",
    "        Wrapper(\n",
    "            n_features_to_select=n_features_to_select,\n",
    "            n_clusters=clusters,\n",
    "            criterion=\"tr\",\n",
    "            clustering_method=\"kmeans\",\n",
    "            random_state=0,\n",
    "        ),\n",
    "    ),\n",
    "    (\n",
    "        \"fsskmeans_ml\",\n",
    "        Wrapper(\n",
    "            n_features_to_select=n_features_to_select,\n",
    "            n_clusters=clusters,\n",
    "            criterion=\"ml\",\n",
    "            clustering_method=\"kmeans\",\n",
    "            random_state=0,\n",
    "        ),\n",
    "    ),\n",
    "]\n",
    "\n",
    "# 辞書の初期化\n",
    "selected_features_index_dict = {}\n",
    "cluster_label_dict = {}\n",
    "cluster_size_dict = {}\n",
    "\n",
    "# 各インスタンスに対して処理を実行\n",
    "for name, instance in instances:\n",
    "    selected_features_index, cluster_label, cluster_size = process_wrapper(\n",
    "        name, instance, X_scaled, y\n",
    "    )\n",
    "    selected_features_index_dict[name] = selected_features_index\n",
    "    cluster_label_dict[name] = cluster_label\n",
    "    cluster_size_dict[name] = cluster_size\n",
    "    print(\"[\", name, \"]\")\n",
    "    print(\"選択された特徴量のインデックス : \", selected_features_index)\n",
    "    print(\"選択された特徴量の数 : \", len(selected_features_index))\n",
    "    print(\"各層のクラスタサイズ : \", cluster_size)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Kmeans, GMMでクラスタリングしたとき"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ kmeans ]\n",
      "各層のクラスタサイズ :  [ 810 2150]\n",
      "\n",
      "[ gmm ]\n",
      "各層のクラスタサイズ :  [ 766 2194]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# k-meansクラスタリングの適用\n",
    "kmeans = KMeans(n_clusters=clusters, random_state=0)\n",
    "kmeans_cluster = kmeans.fit_predict(X_scaled)\n",
    "\n",
    "gmm = GaussianMixture(n_components=clusters, random_state=0, init_params=\"kmeans\")\n",
    "gmm_cluster = gmm.fit_predict(X_scaled)\n",
    "\n",
    "kmeans_size = np.bincount(kmeans_cluster, minlength=clusters)\n",
    "gmm_size = np.bincount(gmm_cluster, minlength=clusters)\n",
    "\n",
    "cluster_label_dict[\"kmeans\"] = kmeans_cluster\n",
    "cluster_label_dict[\"gmm\"] = gmm_cluster\n",
    "cluster_size_dict[\"kmeans\"] = kmeans_size\n",
    "cluster_size_dict[\"gmm\"] = gmm_size\n",
    "\n",
    "methods = [\"kmeans\", \"gmm\"]\n",
    "for name in methods:\n",
    "    print(\"[\", name, \"]\")\n",
    "    print(\"各層のクラスタサイズ : \", cluster_size_dict[name])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------\n",
    "### 標本配分（Allocation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 基底クラス"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseAllocation(metaclass=ABCMeta):  # 抽象基底クラス（ABC）\n",
    "    # 初期化クラス（n_samples(標本サイズ), H(クラスタ数)）\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_samples: int,\n",
    "        H: int,\n",
    "        random_state: int,\n",
    "        criterion: str,\n",
    "        clustering_method: str,\n",
    "    ):\n",
    "        self.n_samples = n_samples\n",
    "        self.H = H\n",
    "        self.random_state = random_state\n",
    "        self.criterion = criterion\n",
    "        self.clustering_method = clustering_method\n",
    "\n",
    "    @abstractmethod\n",
    "    def solve(self, X: NDArray, y: NDArray) -> NDArray:\n",
    "        \"\"\"標本配分を解く\n",
    "\n",
    "        Args:\n",
    "            X (NDArray): データ (N x M)\n",
    "            y (NDArray): 目的変数 (N)\n",
    "\n",
    "        Raises:\n",
    "            NotImplementedError: _description_\n",
    "\n",
    "        Returns:\n",
    "            NDArray: 各クラスタの標本数 (H, )\n",
    "\n",
    "        Note:\n",
    "            M: 特徴量数\n",
    "            H: クラスタ数\n",
    "        \"\"\"\n",
    "        # 具象クラスがsolveメゾッドを実装しない場合はNotImpleamentedErrorが発生\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def clustering(self, X: NDArray) -> tuple[NDArray, NDArray]:\n",
    "        if self.criterion == \"tr\" and self.clustering_method == \"gmm\":\n",
    "            cluster_label = cluster_label_dict[\"fssem_tr\"]\n",
    "            cluster_size = cluster_size_dict[\"fssem_tr\"]\n",
    "        if self.criterion == \"ml\" and self.clustering_method == \"gmm\":\n",
    "            cluster_label = cluster_label_dict[\"fssem_ml\"]\n",
    "            cluster_size = cluster_size_dict[\"fssem_ml\"]\n",
    "        if self.criterion == \"tr\" and self.clustering_method == \"kmeans\":\n",
    "            cluster_label = cluster_label_dict[\"fsskmeans_tr\"]\n",
    "            cluster_size = cluster_size_dict[\"fsskmeans_tr\"]\n",
    "        if self.criterion == \"ml\" and self.clustering_method == \"kmeans\":\n",
    "            cluster_label = cluster_label_dict[\"fsskmeans_ml\"]\n",
    "            cluster_size = cluster_size_dict[\"fsskmeans_ml\"]\n",
    "        if self.criterion == \"none\" and self.clustering_method == \"kmeans\":\n",
    "            cluster_label = cluster_label_dict[\"kmeans\"]\n",
    "            cluster_size = cluster_size_dict[\"kmeans\"]\n",
    "        if self.criterion == \"none\" and self.clustering_method == \"gmm\":\n",
    "            cluster_label = cluster_label_dict[\"gmm\"]\n",
    "            cluster_size = cluster_size_dict[\"gmm\"]\n",
    "\n",
    "        # インスタンス変数として設定\n",
    "        self.cluster_label = cluster_label\n",
    "        self.N = cluster_size\n",
    "        return cluster_label, cluster_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 単純無作為抽出のクラス"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomAllocation(BaseAllocation):\n",
    "    # 抽象メゾッドを具象化\n",
    "    def solve(self, X: NDArray, y: NDArray) -> NDArray:\n",
    "        \"\"\"ランダムにn_samplesの標本を選択する\"\"\"\n",
    "        n = np.array([self.n_samples])\n",
    "        return n\n",
    "\n",
    "    def clustering(self, X: NDArray) -> tuple[NDArray, NDArray]:\n",
    "        # cluster_labelのすべての要素は0（すべてのデータを同じクラスタに属させている）\n",
    "        cluster_label = np.zeros(\n",
    "            X.shape[0]\n",
    "        )  # cluster_label = [0,0,0,,...(要素数：データ数）]\n",
    "        # クラスタサイズ＝データ数\n",
    "        cluster_size = np.array([len(cluster_label)])  # cluster_size=[データ数]\n",
    "        return cluster_label, cluster_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 比例配分のクラス"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProportionalAllocation(BaseAllocation):\n",
    "    def solve(self, X: NDArray, y: NDArray) -> NDArray:\n",
    "        \"\"\"各クラスタ数に比例した標本数で分割する\"\"\"\n",
    "        n: NDArray = np.round(self.N / self.N.sum() * self.n_samples).astype(int)\n",
    "\n",
    "        if n.sum() > self.n_samples:\n",
    "            # nの合計がn_samplesより大きい場合は一番標本数が多いクラスタから削る\n",
    "            n[np.argmax(n)] -= n.sum() - self.n_samples\n",
    "\n",
    "        if n.sum() < self.n_samples:\n",
    "            # nの合計がn_samplesより小さい場合は一番標本数が多いクラスタにたす\n",
    "            n[np.argmax(n)] += -n.sum() + self.n_samples\n",
    "\n",
    "        # for i in range(\n",
    "        #     len(n)\n",
    "        # ):  # nの要素でm_VALUEより小さいものがあれば要素数が最も大きい層から持ってくる\n",
    "        #     if n[i] < m_VALUE:\n",
    "        #         delta = m_VALUE - n[i]\n",
    "        #         n[i] = m_VALUE\n",
    "        #         n[np.argmax(n)] -= delta\n",
    "\n",
    "        return n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 事後層化のクラス"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PostStratification(BaseAllocation):\n",
    "    def solve(self, X: NDArray, y: NDArray) -> NDArray:\n",
    "        \"\"\"ランダムにn_samplesの標本を選択する\"\"\"\n",
    "        n = np.array([self.n_samples])\n",
    "\n",
    "        return n  # （例）n=[標本サイズ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 最適標本配分のクラス"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OptimalAllocation(BaseAllocation):\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_samples: int,\n",
    "        H: int,\n",
    "        m: NDArray,  # 標本サイズ下限\n",
    "        M: Optional[NDArray] = None,  # 標本サイズ上限 #Optional(Noneである可能性がある)\n",
    "        random_state: int = 0,\n",
    "        criterion: str = \"tr\",\n",
    "        clustering_method: str = \"kmeans\",\n",
    "    ):\n",
    "        super().__init__(\n",
    "            n_samples, H, random_state, criterion, clustering_method\n",
    "        )  # 基底クラスBaseAllocation（スーパークラス）の初期化メゾッドを呼び出す\n",
    "        self.m = m  # 各クラスタの最小標本サイズ (H, )\n",
    "        self.M = M  # 各クラスタの最大標本サイズ (H, ), (指定しない場合はクラスタサイズ)\n",
    "\n",
    "    def solve(self, X: NDArray, y: NDArray) -> NDArray:\n",
    "        # S:クラスタ毎の目的変数のvarianceを要素とする配列 (H, )\n",
    "        S = np.array([np.var(y[self.cluster_label == h]) for h in range(self.H)])\n",
    "        d = (self.N**2) * S  # (H, )\n",
    "        n = self._simple_greedy(n=self.m.copy(), d=d)\n",
    "\n",
    "        # 制約チェック\n",
    "        self._check_constraints(n)\n",
    "\n",
    "        return n\n",
    "\n",
    "    def _simple_greedy(self, n: NDArray, d: NDArray) -> NDArray:\n",
    "        M = self.M.copy() if self.M is not None else self.N.copy()\n",
    "        I = np.arange(self.H)  # noqa #クラスタのインデックス\n",
    "        while (n.sum() != self.n_samples) and len(I) != 0:\n",
    "            delta = np.zeros(self.H)\n",
    "            delta[I] = (d / (n + 1) - d / n)[I]\n",
    "            h_star = np.argmin(delta[I])\n",
    "            h_star = I[h_star]\n",
    "\n",
    "            if n[h_star] + 1 <= M[h_star]:\n",
    "                n[h_star] = n[h_star] + 1\n",
    "            else:\n",
    "                # Iの要素h_starを削除\n",
    "                I_ = I.tolist()\n",
    "                I_ = [i for i in I_ if i != h_star]\n",
    "                I = np.array(I_)  # noqa\n",
    "\n",
    "        return n\n",
    "\n",
    "    def _check_constraints(self, n: NDArray):\n",
    "        assert (\n",
    "            n.sum() <= self.n_samples\n",
    "        ), f\"Total sample size is over than {self.n_samples}\"\n",
    "        assert np.all(n >= self.m), \"Minimum sample size constraint is not satisfied\"\n",
    "        if self.M is not None:\n",
    "            assert np.all(\n",
    "                n <= self.M\n",
    "            ), \"Maximum sample size constraint is not satisfied\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 母平均の推定値を計算する関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_y_mean(n: NDArray, cluster_label: NDArray, y: NDArray) -> NDArray:\n",
    "    \"\"\"実際にサンプリングを行って目的変数の平均を推定\n",
    "\n",
    "    Args:\n",
    "        n (NDArray): 各クラスタの標本数 (H, )\n",
    "        cluster_label (NDArray): クラスタラベル (N, )\n",
    "        y (NDArray): 目的変数 (N, )\n",
    "\n",
    "    Returns:\n",
    "        NDArray: 推定された目的変数の平均\n",
    "\n",
    "    Note:\n",
    "        N: データ数\n",
    "        H: クラスタ数\n",
    "    \"\"\"\n",
    "    # cluster_labelからユニークなクラスタラベルを取得し、母集団の各クラスタのサイズNを取得\n",
    "    N = np.unique(cluster_label, return_counts=True)[1]  # クラスタサイズ (H, )\n",
    "    weights = N / N.sum()\n",
    "    y_hat = 0\n",
    "    for h in range(n.shape[0]):  # n.shape[0]:層の数\n",
    "        y_cluster = y[cluster_label == h]\n",
    "        # クラスタ内でランダム n_h サンプリング\n",
    "        sample: NDArray = np.random.choice(y_cluster, n[h], replace=False)\n",
    "        y_sample_mean = sample.mean()  # サンプリングした標本の平均\n",
    "        y_hat += y_sample_mean * weights[h]\n",
    "\n",
    "    return y_hat\n",
    "\n",
    "\n",
    "def estimate_y_mean_post(n: NDArray, cluster_label: NDArray, y: NDArray) -> NDArray:\n",
    "    N = np.unique(cluster_label, return_counts=True)[1]\n",
    "    weights = N / N.sum()\n",
    "    y_hat = 0\n",
    "    indices = np.arange(N.sum())\n",
    "    y_array = np.array(y.tolist())\n",
    "    n_indices = np.random.choice(indices, n[0], replace=False)\n",
    "    n_label = np.array([cluster_label[i] for i in n_indices])\n",
    "    n_new = np.unique(n_label)\n",
    "    for h in n_new:\n",
    "        index = np.where(n_label == h)[0]\n",
    "        sample = y_array[n_indices[index]]\n",
    "        y_sample_mean = sample.mean()  # サンプリングした標本の平均\n",
    "        y_hat += y_sample_mean * weights[h]\n",
    "    return y_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 各ポリシーを生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 各ポリシーの生成を行う関数\n",
    "def create_policies(\n",
    "    criterion_list: list[str],\n",
    "    clustering_method_list: list[str],\n",
    "    n_samples: int,\n",
    "    H: int,\n",
    "    random_state: int,\n",
    "    m_value: int,\n",
    ") -> dict[list[str] : list[BaseAllocation]]:\n",
    "    policies_dict = {}\n",
    "    for criterion in criterion_list:\n",
    "        for clustering_method in clustering_method_list:\n",
    "            policies: list[BaseAllocation] = [\n",
    "                RandomAllocation(\n",
    "                    n_samples=n_samples,\n",
    "                    H=H,\n",
    "                    random_state=random_state,\n",
    "                    criterion=criterion,\n",
    "                    clustering_method=clustering_method,\n",
    "                ),\n",
    "                ProportionalAllocation(\n",
    "                    n_samples=n_samples,\n",
    "                    H=H,\n",
    "                    random_state=random_state,\n",
    "                    criterion=criterion,\n",
    "                    clustering_method=clustering_method,\n",
    "                ),\n",
    "                PostStratification(\n",
    "                    n_samples=n_samples,\n",
    "                    H=H,\n",
    "                    random_state=random_state,\n",
    "                    criterion=criterion,\n",
    "                    clustering_method=clustering_method,\n",
    "                ),\n",
    "                OptimalAllocation(\n",
    "                    n_samples=n_samples,\n",
    "                    H=H,\n",
    "                    random_state=random_state,\n",
    "                    m=np.full(H, m_value),\n",
    "                    M=None,\n",
    "                    criterion=criterion,\n",
    "                    clustering_method=clustering_method,\n",
    "                ),\n",
    "            ]\n",
    "            policies_dict[(criterion, clustering_method)] = policies\n",
    "    return policies_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------\n",
    "### 母平均の推定と分散の計算"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 結果の出力"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "policies_dict = create_policies(\n",
    "    CRITERION_LIST, CLUSTERING_METHOD_LIST, N_SAMPLES, H, RANDOM_STATE, m_VALUE\n",
    ")\n",
    "\n",
    "\n",
    "def cauculate_reduction_rate(\n",
    "    X: pd.DataFrame, y: pd.DataFrame, policies_dict: dict\n",
    ") -> dict:\n",
    "    reduction_rate_dict = {}\n",
    "    allocations_dict = {}\n",
    "    for method, policies in policies_dict.items():\n",
    "        # それぞれの戦略で各クラスタの標本数を求解\n",
    "        allocations: list[dict] = []  # 各戦略の実行結果が辞書形式で追加される\n",
    "        for policy in policies:\n",
    "            # policyを用いてXをクラスタリング\n",
    "            cluster_label, _ = policy.clustering(X_scaled)\n",
    "            n = policy.solve(X_scaled, y)\n",
    "            allocations.append(\n",
    "                {\n",
    "                    \"policy\": policy.__class__.__name__,\n",
    "                    \"n\": n,\n",
    "                    \"cluster_label\": cluster_label,\n",
    "                }\n",
    "            )\n",
    "        allocations_dict[method] = allocations\n",
    "\n",
    "    # 各戦略の標本数に基づいて目的変数の平均を推定\n",
    "    y_hats_dict = {}\n",
    "    for method, allocations in allocations_dict.items():\n",
    "        y_hats = []\n",
    "        for random_state in range(N_TRIALS):\n",
    "            for allocation in allocations:\n",
    "                if allocation[\"policy\"] == \"PostStratification\":\n",
    "                    y_hat = estimate_y_mean_post(\n",
    "                        allocation[\"n\"], allocation[\"cluster_label\"], y\n",
    "                    )\n",
    "                else:\n",
    "                    y_hat = estimate_y_mean(\n",
    "                        allocation[\"n\"], allocation[\"cluster_label\"], y\n",
    "                    )\n",
    "                y_hats.append(\n",
    "                    {\n",
    "                        \"policy\": allocation[\"policy\"],\n",
    "                        \"y_hat\": y_hat,\n",
    "                        \"random_state\": random_state,\n",
    "                    }\n",
    "                )\n",
    "        y_hats_dict[method] = y_hats\n",
    "\n",
    "    method_list = []\n",
    "    for method, y_hats in y_hats_dict.items():\n",
    "        y_hat_df = pd.DataFrame(y_hats)\n",
    "        y_hat_df[\"error\"] = (\n",
    "            y_hat_df[\"y_hat\"] - y.mean()\n",
    "        )  # 真の平均からの誤差をerrorカラムに追加\n",
    "\n",
    "        # random_allocationの誤差分散\n",
    "        random_allocation_std = y_hat_df[y_hat_df[\"policy\"] == \"RandomAllocation\"][\n",
    "            \"error\"\n",
    "        ].var()\n",
    "        # random_allocation以外の誤差分散\n",
    "        non_random_allocation_std = (\n",
    "            y_hat_df[y_hat_df[\"policy\"] != \"RandomAllocation\"]\n",
    "            .groupby(\"policy\")[\"error\"]\n",
    "            .var()\n",
    "        )\n",
    "\n",
    "        # 削減率\n",
    "        reduction_rate = (1 - non_random_allocation_std / random_allocation_std) * 100\n",
    "\n",
    "        ## policyの順番をpoliciesの順番に調整\n",
    "        reduction_rate = reduction_rate.reindex(\n",
    "            [policy.__class__.__name__ for policy in policies]\n",
    "        )\n",
    "\n",
    "        reduction_rate_dict[method] = reduction_rate\n",
    "        method_list.append(method)\n",
    "\n",
    "    return reduction_rate_dict, method_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "criterion: ml clustering_method: gmm\n",
      "{'RandomAllocation': nan, 'ProportionalAllocation': 2.708327146079284, 'PostStratification': -0.02018354447985491, 'OptimalAllocation': 2.433973375950033}\n",
      "criterion: ml clustering_method: kmeans\n",
      "{'RandomAllocation': nan, 'ProportionalAllocation': 5.351048221621445, 'PostStratification': 5.838652642955347, 'OptimalAllocation': 15.503740276136819}\n",
      "criterion: tr clustering_method: gmm\n",
      "{'RandomAllocation': nan, 'ProportionalAllocation': 0.002081812889100654, 'PostStratification': -3.389871387326837, 'OptimalAllocation': 0.48776757873077675}\n",
      "criterion: tr clustering_method: kmeans\n",
      "{'RandomAllocation': nan, 'ProportionalAllocation': 6.008287678709548, 'PostStratification': 3.603671414581598, 'OptimalAllocation': 12.308107067879977}\n",
      "criterion: none clustering_method: gmm\n",
      "{'RandomAllocation': nan, 'ProportionalAllocation': -0.8405579747935032, 'PostStratification': 0.41350809415199946, 'OptimalAllocation': 1.4096322052462187}\n",
      "criterion: none clustering_method: kmeans\n",
      "{'RandomAllocation': nan, 'ProportionalAllocation': 1.4968564959589847, 'PostStratification': -0.8539317533585422, 'OptimalAllocation': 12.50894757672108}\n",
      "criterion: ml clustering_method: gmm\n",
      "{'RandomAllocation': [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan], 'ProportionalAllocation': [10.003236523564352, 6.098956153373381, -4.047136522306172, 7.981571435398449, 2.931326657114841, 9.778958539916117, 4.550200277734184, 1.0409783771915593, -7.033945566554123, -4.2208744146397414], 'PostStratification': [1.8207320856679199, 4.259187003586784, -7.940569106290463, -0.04806372395618208, 9.846091815621316, -2.378940500148108, -9.234130987636835, 6.38446724879167, -3.4624001878400756, 0.551790907405425], 'OptimalAllocation': [5.388853550775563, 4.142237431527107, 3.7266063725848286, -3.506989043795783, 12.335788089640742, 5.123027381255341, -2.2047936660746004, 2.707416429290088, 4.179817409653063, -7.5522301953560245]}\n",
      "criterion: ml clustering_method: kmeans\n",
      "{'RandomAllocation': [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan], 'ProportionalAllocation': [-11.837750362755939, 10.453334046361984, 2.9997046790106507, 13.229721061034216, 7.171297354247985, 16.608840922733513, 2.286895843229231, 8.137459787228984, 7.031331348293768, -2.570352463169945], 'PostStratification': [4.306023838401818, 5.872604562892558, 4.619811897484238, 14.472359057594709, 0.3911743354232611, 6.965602339595289, 0.5392578992232, 7.910709256054105, 12.372933265597553, 0.9360499772867459], 'OptimalAllocation': [19.661152832277306, 19.862665986401716, 22.27880984758834, 19.849146805139107, 11.58461266409645, 17.627599967033667, 6.045849127117853, 15.108572623768312, 13.15776431148884, 9.861228596456584]}\n",
      "criterion: tr clustering_method: gmm\n",
      "{'RandomAllocation': [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan], 'ProportionalAllocation': [1.0461182513128553, -5.664234425063297, 7.7824013643290275, -9.641179258518907, 1.239598714266399, 2.4548945533678035, 8.216346209702118, 0.24682549581848123, -5.7315022535858295, 0.07154947726235594], 'PostStratification': [-4.1197450261300395, -0.1364990953041323, 14.247913086149621, -6.171959975255459, 1.0948279587099097, -15.857831215331952, -7.724338052447632, -0.7744127964024461, -15.570665655687188, 1.1139968984309467], 'OptimalAllocation': [4.698621015914783, -0.24466908108149443, 6.140933917630164, -12.11772077520843, -0.6980298624911674, 2.97076606229405, 1.4994315043235562, 2.5039099367094586, 0.43282047843787863, -0.3083874092210337]}\n",
      "criterion: tr clustering_method: kmeans\n",
      "{'RandomAllocation': [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan], 'ProportionalAllocation': [-2.5651624213406388, 8.776475887991964, 12.01634382045298, -1.6273654889869649, 13.559033160061752, 5.2166825487427015, -0.4124114155409364, 5.817019670223155, 10.390677072953658, 8.911583952537816], 'PostStratification': [-5.319298657396643, -1.3473108036651027, 3.427688793799899, 6.076765188617372, 7.651380464085422, 3.3603453704921016, 0.6466195533122887, 4.268025848459123, 8.990373798991646, 8.282124589119878], 'OptimalAllocation': [-0.11451757346976343, 20.362454111406446, 6.491539554175752, 14.069868148182941, 12.189838310703859, 10.024139359025241, 17.824558904528796, 12.073810563127395, 13.34344999920397, 16.815929301915123]}\n",
      "criterion: none clustering_method: gmm\n",
      "{'RandomAllocation': [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan], 'ProportionalAllocation': [4.152702097670002, 4.809648330101412, -3.2143332489676046, 4.32961970459732, -0.05299636216622439, -2.891194825475485, -0.0046573538237781875, -5.040426212482485, -11.210206394719435, 0.7162645173312443], 'PostStratification': [0.6254428045826432, -1.2143655250440144, -12.50823420415006, 11.24133257376072, -5.2889417448219955, 0.8908660735792773, 6.464374833715358, 1.7200125461878102, -1.8938987645576333, 4.09849234826789], 'OptimalAllocation': [3.3310773965882, -2.598518946886408, -3.735263117491061, 7.598315793968668, -7.612766954176542, 4.26875418910706, 9.715569339633257, 2.632627091564199, 2.7494591969654314, -2.2529319368106204]}\n",
      "criterion: none clustering_method: kmeans\n",
      "{'RandomAllocation': [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan], 'ProportionalAllocation': [-2.1701159575557627, 5.466789365022495, -2.809629796276636, 4.023945471492862, 6.878838767135953, 5.776826694201064, 2.7365075442334463, -7.283247358028899, 1.270444736435905, 1.0782054929294183], 'PostStratification': [-4.761504103696379, 4.975914783753, -16.183239875479984, 1.0352510814362947, 0.8768612341465643, 2.0080180104959933, -4.750497889948546, 1.2961547383086303, 1.2010877894300331, 5.76263669796897], 'OptimalAllocation': [2.9120022600994, 22.596694852433142, 13.594109020473377, 18.886046122564903, 9.63119352525692, 15.122619041913287, 15.165679356837192, 8.491638285173064, 7.626397042893663, 11.063096259565864]}\n"
     ]
    }
   ],
   "source": [
    "_, methods = cauculate_reduction_rate(X_scaled, y, policies_dict)\n",
    "\n",
    "all_results = []\n",
    "for i in range(N_EXPERIMENT):\n",
    "    dict, _ = cauculate_reduction_rate(X_scaled, y, policies_dict)\n",
    "    all_results.append(dict)\n",
    "\n",
    "\n",
    "results = {}\n",
    "for method in methods:\n",
    "    results[method] = {\n",
    "        \"RandomAllocation\": [],\n",
    "        \"ProportionalAllocation\": [],\n",
    "        \"PostStratification\": [],\n",
    "        \"OptimalAllocation\": [],\n",
    "    }\n",
    "for dict in all_results:\n",
    "    for method, policy in dict.items():\n",
    "        for allocation_method in list(policy.index):\n",
    "            results[method][allocation_method].append(policy[allocation_method])\n",
    "\n",
    "\n",
    "final_results = {}\n",
    "for method in methods:\n",
    "    final_results[method] = {\n",
    "        \"RandomAllocation\": [],\n",
    "        \"ProportionalAllocation\": [],\n",
    "        \"PostStratification\": [],\n",
    "        \"OptimalAllocation\": [],\n",
    "    }\n",
    "for method, dict in results.items():\n",
    "    for allocation_method in list(dict.keys()):\n",
    "        final_results[method][allocation_method] = np.mean(\n",
    "            np.array(dict[allocation_method])\n",
    "        )\n",
    "\n",
    "\n",
    "for method, dict in final_results.items():\n",
    "    print(\"criterion:\", method[0], \"clustering_method:\", method[1])\n",
    "    print(dict)\n",
    "for method, dict in results.items():\n",
    "    print(\"criterion:\", method[0], \"clustering_method:\", method[1])\n",
    "    print(dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

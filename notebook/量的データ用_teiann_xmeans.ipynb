{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 量的データ用（For quantitaive data）\n",
    "[Methods]  \n",
    "- Clustering methods : Kmeans, GMM, FSSEM, FSS-Kmeans    \n",
    "- Allocation methods : random, proportional allocation, post stratification, optimal allocation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------\n",
    "### ライブラリのインポート＆その他の設定（Importing Libraries & Other Settings）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 8\n"
     ]
    }
   ],
   "source": [
    "# 基本的なライブラリ\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy.typing import NDArray\n",
    "from scipy import stats\n",
    "\n",
    "# Scikit-learn関連\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.utils.validation import check_X_y\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "# 抽象基底クラス (ABC)\n",
    "from abc import ABCMeta, abstractmethod\n",
    "\n",
    "# タイピングのサポート\n",
    "from typing import Optional\n",
    "\n",
    "# シード設定\n",
    "from lightning.pytorch import seed_everything\n",
    "\n",
    "seed_everything(8)\n",
    "\n",
    "# 可視化の設定\n",
    "import matplotlib.pyplot as plt\n",
    "import japanize_matplotlib\n",
    "import itertools\n",
    "\n",
    "plt.style.use(\"ggplot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------\n",
    "### 実験設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_SIZE = 100  # 標本サイズ\n",
    "DATA_SIZE = 10000  # データサイズ(df2)\n",
    "N_TRIALS = 10  # 試行回数（標本平均を求める回数）\n",
    "N_EXPERIMENT = 1  # 分散を求める回数\n",
    "m_VALUE = 2  # 各クラスタの最小標本数(最適標本配分)\n",
    "RANDOM_STATE = 0  # 乱数シード\n",
    "ALLOCATION_METHODS = [\n",
    "    \"ProportionalAllocation\",\n",
    "    \"PostStratification\",\n",
    "    \"OptimalAllocation\",\n",
    "]  # \"RandomAllocation\"はいれない\n",
    "CLUSTERING_METHOD = \"xmeans\"  # \"gmm\" or \"kmeans\" or \"xmeans\"\n",
    "\n",
    "# クラスタを固定する場合(gmm, kmeans)\n",
    "N_CLUSTERS = 2  # クラスタ数\n",
    "\n",
    "# クラスタ数を固定しない場合（xmeans)\n",
    "K_MIN = 2\n",
    "K_MAX = 10\n",
    "\n",
    "\n",
    "MAXIMUM_FEATURES_TO_SELECT = 10  # 選択される最大の特徴量数\n",
    "\n",
    "SELECTING_FEATURES = (\n",
    "    \"all_features\"  # \"all_features\" or \"not_all_features\" #特徴量をすべて選ぶかどうか\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------\n",
    "### データの前処理（Data Preprocessing）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 外れ値を除去する関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 外れ値の除去\n",
    "def remove_outliers_zscore(\n",
    "    data: pd.DataFrame, metric: str, threshold: float = 2\n",
    ") -> pd.DataFrame:\n",
    "    z_scores = np.abs(stats.zscore(data[metric]))\n",
    "    data = data[(z_scores < threshold)]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### メルカリデータ（df1：全部, df2：一部）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df1(all the data)\n",
    "df1 = pd.read_csv(\n",
    "    R\"C:\\Users\\HaruMomozu\\Documents\\aug_first_cpn_data_for_ab_test_sensibility_tsukuba.csv\"\n",
    ")\n",
    "obj1 = \"GMV\"\n",
    "features_list1 = [\n",
    "    \"hist_4_day_buy_num\",\n",
    "    \"hist_4_day_gmv\",\n",
    "    \"his_4_day_is_buy\",\n",
    "    \"hist_30_day_buy_days\",\n",
    "    \"hist_30_day_buy_num\",\n",
    "    \"hist_30_day_gmv\",\n",
    "    \"hist_30_day_buy_recency\",\n",
    "    \"hist_30_day_pay_days\",\n",
    "    \"hist_30_day_atpu\",\n",
    "    \"hist_30_day_gpv\",\n",
    "    \"hist_30_day_pay_recency\",\n",
    "    \"hist_30_day_list_days\",\n",
    "    \"hist_30_day_list_num\",\n",
    "    \"hist_30_day_list_recency\",\n",
    "    \"hist_30_day_like_count\",\n",
    "    \"hist_30_day_like_count_not_deleted\",\n",
    "    \"hist_30_day_like_recency\",\n",
    "]\n",
    "\n",
    "# df2(subset of the data)\n",
    "df2 = df1.iloc[:DATA_SIZE]\n",
    "obj2 = obj1\n",
    "features_list2 = features_list1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 外れ値除去と標準化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df2  # choose from (df1, df2)\n",
    "obj = obj2  # choose from (obj1, obj2)\n",
    "features_list = features_list2  # choose from (features_list1, features_list2)\n",
    "\n",
    "# 外れ値除去\n",
    "df = remove_outliers_zscore(df, obj)\n",
    "\n",
    "# 標準化\n",
    "X = df[features_list]\n",
    "scaler = StandardScaler()\n",
    "scaled_features = scaler.fit_transform(X)\n",
    "X_scaled = pd.DataFrame(scaled_features, columns=features_list)\n",
    "\n",
    "# 目的変数\n",
    "y = df[obj]\n",
    "\n",
    "# 行を詰める\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------\n",
    "### 提案手法でクラスタリング"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Allocation_in_Wrapper Class\n",
    "とりあえずproportional でやってみる  \n",
    "・データによってはクラスタ数=3と指定した場合も2になることもある  \n",
    "⇒ この場合はscore = 0 にする"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Allocation_in_Wrapper(BaseEstimator, TransformerMixin):\n",
    "    def __init__(\n",
    "        self,\n",
    "        maximum_features_to_select: int,\n",
    "        n_clusters: int,\n",
    "        clustering_method: str = \"kmeans\",\n",
    "        allocation_methods: list[str] = [\"ProportionalAllocation\"],\n",
    "        sample_size: int = 10,\n",
    "        n_trials: int = 100,\n",
    "        m_value=2,\n",
    "        M: Optional[NDArray] = None,\n",
    "        random_state: int = 0,\n",
    "        selecting_features: str = \"all_features\",\n",
    "        k_min: int = 2,\n",
    "        k_max: int = 10,\n",
    "    ):\n",
    "        self.maximum_features_to_select = maximum_features_to_select\n",
    "        self.n_clusters = n_clusters\n",
    "        self.clustering_method = clustering_method\n",
    "        self.allocation_methods = allocation_methods\n",
    "        self.sample_size = sample_size\n",
    "        self.n_trials = n_trials\n",
    "        self.m_value = m_value\n",
    "        self.M = M\n",
    "        self.random_state = random_state\n",
    "        self.selecting_features = selecting_features\n",
    "        self.k_min = k_min\n",
    "        self.k_max = k_max\n",
    "\n",
    "    def fss(\n",
    "        self, X: pd.DataFrame, y: pd.DataFrame\n",
    "    ) -> \"Allocation_in_Wrapper\":  ###これ自体は多分あってる\n",
    "        X, y = check_X_y(X, y)\n",
    "        n_features = X.shape[1]  # 総特徴量数\n",
    "        self.selected_features_dict = {}\n",
    "        self.final_cluster_assignments_dict = {}\n",
    "        self.features_score_dict = {}\n",
    "        self.final_n_clusters_dict = {}\n",
    "\n",
    "        # ランダムの分散を計算\n",
    "        self.random_allocation_std = self.cauculate_random_std(X, y)\n",
    "        print(\"random_std\", self.random_allocation_std)\n",
    "\n",
    "        # 特徴量選択\n",
    "        for allocation_method in self.allocation_methods:\n",
    "            print(\"[\", allocation_method, \"]\")\n",
    "\n",
    "            features_score_dict = {}  # 確認用\n",
    "\n",
    "            # 選ばれた特徴量と残っている特徴量の初期化\n",
    "            current_features = []\n",
    "            remaining_features = list(range(n_features))\n",
    "            if self.selecting_features == \"not_all_features\":\n",
    "                best_score = -np.inf\n",
    "\n",
    "            while len(current_features) < self.maximum_features_to_select:\n",
    "                if self.selecting_features == \"all_features\":\n",
    "                    best_score = -np.inf\n",
    "                    best_labels = [-1 for i in range(len(X))]\n",
    "                    best_n_clusters = -1\n",
    "                best_feature = None  # 選ぶ特徴量の初期化\n",
    "\n",
    "                for feature in remaining_features:\n",
    "                    temp_features = tuple(\n",
    "                        current_features + [feature]\n",
    "                    )  # 特徴量をひとつ加え、score計算    ###########ここまでok\n",
    "                    print(\"temp_features\", temp_features)\n",
    "                    score, labels, n_clusters = self.crit(\n",
    "                        X[:, temp_features], y, allocation_method\n",
    "                    )\n",
    "                    print(\"score\", score)\n",
    "                    if score > best_score:\n",
    "                        print(\"特徴量更新\")\n",
    "                        best_score = score\n",
    "                        best_feature = feature\n",
    "                        best_labels = labels\n",
    "                        best_n_clusters = n_clusters\n",
    "\n",
    "                if best_feature is not None:\n",
    "                    current_features.append(\n",
    "                        best_feature\n",
    "                    )  # best feature をcurrent features に追加\n",
    "                    num_of_features = len(current_features)\n",
    "                    self.y_hat_df_random = self.cauculate_random_std(X, y)\n",
    "                    print(\n",
    "                        \"num_of_features:\",\n",
    "                        num_of_features,\n",
    "                        \"current_features:\",\n",
    "                        current_features,\n",
    "                        \", score:\",\n",
    "                        best_score,\n",
    "                        \"best_n_clusters:\",\n",
    "                        best_n_clusters,\n",
    "                    )\n",
    "\n",
    "                    features_score_dict[str(num_of_features)] = best_score  # 確認用\n",
    "\n",
    "                    remaining_features.remove(\n",
    "                        best_feature\n",
    "                    )  # best feature をremaining features から取り除く\n",
    "                    self.selected_features_ = current_features\n",
    "                else:\n",
    "                    break\n",
    "\n",
    "            self.final_cluster_assignments_dict[allocation_method] = best_labels\n",
    "            self.final_n_clusters_dict[allocation_method] = best_n_clusters\n",
    "            self.features_score_dict[allocation_method] = features_score_dict\n",
    "            self.selected_features_dict[allocation_method] = self.selected_features_\n",
    "\n",
    "        return self\n",
    "\n",
    "    def crit(\n",
    "        self, X: pd.DataFrame, y: pd.DataFrame, allocation_method: str\n",
    "    ) -> float:  ##これ自体は大丈夫\n",
    "        # クラスタリング手法がGMMの場合\n",
    "        if self.clustering_method == \"gmm\":\n",
    "            model = GaussianMixture(\n",
    "                n_components=self.n_clusters,\n",
    "                random_state=self.random_state,\n",
    "                init_params=\"kmeans\",\n",
    "            )\n",
    "        # クラスタリング手法がKMEANSの場合\n",
    "        if self.clustering_method == \"kmeans\":\n",
    "            model = KMeans(\n",
    "                n_clusters=self.n_clusters,\n",
    "                random_state=self.random_state,\n",
    "            )\n",
    "        if self.clustering_method == \"xmeans\":\n",
    "            model, n_clusters = self.xmeans(X)\n",
    "\n",
    "        model.fit(X)\n",
    "        self.N_cluster_label = model.predict(X)\n",
    "        unique_labels, counts = np.unique(self.N_cluster_label, return_counts=True)\n",
    "        n_clusters = np.sum(counts > 0)  # 空でないクラスタの数\n",
    "        self.N_cluster_size = np.bincount(self.N_cluster_label)\n",
    "\n",
    "        #\n",
    "        error_variance_reduction_rate = self.cauculate_reduction_rate(\n",
    "            X, y, allocation_method\n",
    "        )\n",
    "        score = error_variance_reduction_rate\n",
    "        labels = self.N_cluster_label\n",
    "        return score, labels, n_clusters\n",
    "\n",
    "    def compute_bic(self, X, kmeans):\n",
    "        # クラスタリング結果の取得\n",
    "        labels = kmeans.labels_\n",
    "        clusters = kmeans.cluster_centers_\n",
    "        n_clusters = len(clusters)\n",
    "        n = len(X)\n",
    "        m = X.shape[1]\n",
    "        # クラスター内の分散の合計\n",
    "        variance = np.sum(\n",
    "            [\n",
    "                np.linalg.norm(X[labels == i] - clusters[i], axis=1).sum()\n",
    "                for i in range(n_clusters)\n",
    "            ]\n",
    "        )\n",
    "        # BIC の計算\n",
    "        bic = np.log(n) * n_clusters * m + n * np.log(variance / n)\n",
    "        return bic\n",
    "\n",
    "    def xmeans(self, X):\n",
    "        kmeans = KMeans(n_clusters=self.k_min)  # 初期クラスター数で KMeans を実行\n",
    "        kmeans.fit(X)\n",
    "        best_bic = self.compute_bic(X, kmeans)\n",
    "        best_kmeans = kmeans\n",
    "        best_k = self.k_min\n",
    "        for k in range(self.k_min + 1, self.k_max + 1):\n",
    "            kmeans = KMeans(n_clusters=k)\n",
    "            kmeans.fit(X)\n",
    "            # BIC を計算\n",
    "            current_bic = self.compute_bic(X, kmeans)\n",
    "            # BIC が改善される場合、クラスタ数を更新\n",
    "            if current_bic < best_bic:\n",
    "                best_bic = current_bic\n",
    "                best_kmeans = kmeans\n",
    "                best_k = k\n",
    "        # 最適なクラスタリング結果を返す\n",
    "        return best_kmeans, best_k\n",
    "\n",
    "    def cauculate_reduction_rate(\n",
    "        self, X: pd.DataFrame, y: pd.DataFrame, allocation_method: str\n",
    "    ) -> float:  ######これ自体は大丈夫\n",
    "        # 各戦略の標本数に基づいて目的変数の平均を推定\n",
    "        y_hats = []\n",
    "        for random_state in range(N_TRIALS):\n",
    "            if allocation_method == \"PostStratification\":\n",
    "                y_hat = self.estimate_y_mean_post(X, y)\n",
    "            else:\n",
    "                y_hat = self.estimate_y_mean_other(X, y, allocation_method)\n",
    "            y_hats.append(\n",
    "                {\n",
    "                    \"policy\": allocation_method,\n",
    "                    \"y_hat\": y_hat,\n",
    "                    \"random_state\": random_state,\n",
    "                }\n",
    "            )\n",
    "\n",
    "        y_hat_df = pd.DataFrame(y_hats)\n",
    "        y_hat_df[\"error\"] = (\n",
    "            y_hat_df[\"y_hat\"] - y.mean()\n",
    "        )  # 真の平均からの誤差をerrorカラムに追加\n",
    "\n",
    "        non_random_allocation_std = y_hat_df[\"error\"].var()\n",
    "        # 削減率\n",
    "        reduction_rate = (\n",
    "            1 - non_random_allocation_std / self.random_allocation_std\n",
    "        ) * 100\n",
    "\n",
    "        return reduction_rate\n",
    "\n",
    "    def cauculate_random_std(self, X, y):  # 多分あってる\n",
    "        y_hats = []\n",
    "        for random_state in range(self.n_trials):\n",
    "            sample = np.random.choice(y, self.sample_size, replace=False)\n",
    "            y_hat_random = sample.mean()\n",
    "            y_hats.append(\n",
    "                {\n",
    "                    \"policy\": \"RandomAllocation\",\n",
    "                    \"y_hat\": y_hat_random,\n",
    "                    \"random_state\": random_state,\n",
    "                }\n",
    "            )\n",
    "\n",
    "        y_hat_df = pd.DataFrame(y_hats)\n",
    "        y_hat_df[\"error\"] = y_hat_df[\"y_hat\"] - y.mean()\n",
    "        random_allocation_std = y_hat_df[\"error\"].var()\n",
    "        return random_allocation_std\n",
    "\n",
    "    def estimate_y_mean_post(self, X, y) -> float:  # あってそう\n",
    "        n_cluster_size = np.array([self.sample_size])\n",
    "\n",
    "        weights = self.N_cluster_size / self.N_cluster_size.sum()\n",
    "        y_hat = 0\n",
    "        indices = np.arange(self.N_cluster_size.sum())\n",
    "        y_array = np.array(y.tolist())\n",
    "        n_indices = np.random.choice(indices, n_cluster_size[0], replace=False)\n",
    "        n_label = np.array([self.N_cluster_label[i] for i in n_indices])\n",
    "        n_new_labels = np.unique(n_label)\n",
    "        for h in n_new_labels:\n",
    "            index = np.where(n_label == h)[0]\n",
    "            sample = y_array[n_indices[index]]\n",
    "            y_sample_mean = sample.mean()  # サンプリングした標本の平均\n",
    "            y_hat += y_sample_mean * weights[h]\n",
    "        return y_hat\n",
    "\n",
    "    def estimate_y_mean_other(self, X, y, allocation_method) -> float:  # 多分あっている\n",
    "        if allocation_method == \"ProportionalAllocation\":\n",
    "            n_cluster_size = self.ProportionalAllocation(X, y)\n",
    "        if allocation_method == \"OptimalAllocation\":\n",
    "            n_cluster_size = self.OptimalAllocation(X, y)\n",
    "\n",
    "        weights = self.N_cluster_size / self.N_cluster_size.sum()\n",
    "        y_hat = 0\n",
    "        for h in range(n_cluster_size.shape[0]):\n",
    "            if n_cluster_size[h] != 0:\n",
    "                y_cluster = y[self.N_cluster_label == h]\n",
    "\n",
    "                sample: NDArray = np.random.choice(\n",
    "                    y_cluster, n_cluster_size[h], replace=False\n",
    "                )\n",
    "                y_sample_mean = sample.mean()  # サンプリングした標本の平均\n",
    "                y_hat += y_sample_mean * weights[h]\n",
    "        return y_hat\n",
    "\n",
    "    def get_feature_index_out(self) -> dict[NDArray]:\n",
    "        return self.selected_features_dict  # 選択された特徴量のインデックス\n",
    "\n",
    "    def get_final_cluster_assignments(self) -> dict[NDArray]:\n",
    "        return self.final_cluster_assignments_dict  # 最終的なクラスタリング結果\n",
    "\n",
    "    def get_features_score(self) -> dict[dict]:\n",
    "        return self.features_score_dict\n",
    "\n",
    "    def get_final_n_clusters_dict(self) -> dict:\n",
    "        return self.get_final_n_clusters_dict\n",
    "\n",
    "    def ProportionalAllocation(self, X, y) -> NDArray:  # あってそう\n",
    "        n_cluster_size: NDArray = np.round(\n",
    "            self.N_cluster_size / self.N_cluster_size.sum() * self.sample_size\n",
    "        ).astype(int)\n",
    "\n",
    "        if n_cluster_size.sum() > self.sample_size:\n",
    "            # nの合計がn_samplesより大きい場合は一番標本数が多いクラスタから削る\n",
    "            n_cluster_size[np.argmax(n_cluster_size)] -= (\n",
    "                n_cluster_size.sum() - self.sample_size\n",
    "            )\n",
    "        if n_cluster_size.sum() < self.sample_size:\n",
    "            # nの合計がn_samplesより小さい場合は一番標本数が多いクラスタにたす\n",
    "            n_cluster_size[np.argmax(n_cluster_size)] += (\n",
    "                -n_cluster_size.sum() + self.sample_size\n",
    "            )\n",
    "\n",
    "        return n_cluster_size\n",
    "\n",
    "    def OptimalAllocation(self, X, y) -> NDArray:  # たぶんあってる\n",
    "        self.m = np.full(self.n_clusters, self.m_value)\n",
    "        # S:クラスタ毎の目的変数のvarianceを要素とする配列 (H, )\n",
    "        S = np.array(\n",
    "            [np.var(y[self.N_cluster_label == h]) for h in range(self.n_clusters)]\n",
    "        )\n",
    "        d = (self.N_cluster_size**2) * S\n",
    "\n",
    "        n_cluster_size = self.m.copy()  # 初期値\n",
    "\n",
    "        M = self.M.copy() if self.M is not None else self.N_cluster_size.copy()\n",
    "        I = np.arange(self.n_clusters)  # noqa #クラスタのインデックス\n",
    "        while (n_cluster_size.sum() != self.sample_size) and len(I) != 0:\n",
    "            delta = np.zeros(self.n_clusters)\n",
    "            delta[I] = (d / (n_cluster_size + 1) - d / n_cluster_size)[I]\n",
    "            h_star = np.argmin(delta[I])\n",
    "            h_star = I[h_star]\n",
    "\n",
    "            if n_cluster_size[h_star] + 1 <= M[h_star]:\n",
    "                n_cluster_size[h_star] = n_cluster_size[h_star] + 1\n",
    "            else:\n",
    "                # Iの要素h_starを削除\n",
    "                I_ = I.tolist()\n",
    "                I_ = [i for i in I_ if i != h_star]\n",
    "                I = np.array(I_)  # noqa\n",
    "\n",
    "        # 制約チェック\n",
    "        assert (\n",
    "            n_cluster_size.sum() <= self.sample_size\n",
    "        ), f\"Total sample size is over than {self.sample_size}\"\n",
    "        assert np.all(\n",
    "            n_cluster_size >= self.m\n",
    "        ), \"Minimum sample size constraint is not satisfied\"\n",
    "        if self.M is not None:\n",
    "            assert np.all(\n",
    "                n_cluster_size <= self.M\n",
    "            ), \"Maximum sample size constraint is not satisfied\"\n",
    "\n",
    "        return n_cluster_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random_std 158853.9410455556\n",
      "[ ProportionalAllocation ]\n",
      "temp_features (0,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HaruMomozu\\Desktop\\momozu\\ABtesting\\.venv\\Lib\\site-packages\\threadpoolctl.py:1214: RuntimeWarning: \n",
      "Found Intel OpenMP ('libiomp') and LLVM OpenMP ('libomp') loaded at\n",
      "the same time. Both libraries are known to be incompatible and this\n",
      "can cause random crashes or deadlocks on Linux when loaded in the\n",
      "same Python program.\n",
      "Using threadpoolctl may cause crashes or deadlocks. For more\n",
      "information and possible workarounds, please see\n",
      "    https://github.com/joblib/threadpoolctl/blob/master/multiple_openmp.md\n",
      "\n",
      "  warnings.warn(msg, RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score -68.38285612646577\n",
      "特徴量更新\n",
      "temp_features (1,)\n",
      "score -83.01109166030803\n",
      "temp_features (2,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HaruMomozu\\Desktop\\momozu\\ABtesting\\.venv\\Lib\\site-packages\\sklearn\\base.py:1473: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (3). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\HaruMomozu\\Desktop\\momozu\\ABtesting\\.venv\\Lib\\site-packages\\sklearn\\base.py:1473: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\HaruMomozu\\Desktop\\momozu\\ABtesting\\.venv\\Lib\\site-packages\\sklearn\\base.py:1473: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\HaruMomozu\\Desktop\\momozu\\ABtesting\\.venv\\Lib\\site-packages\\sklearn\\base.py:1473: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\HaruMomozu\\Desktop\\momozu\\ABtesting\\.venv\\Lib\\site-packages\\sklearn\\base.py:1473: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\HaruMomozu\\Desktop\\momozu\\ABtesting\\.venv\\Lib\\site-packages\\sklearn\\base.py:1473: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\HaruMomozu\\Desktop\\momozu\\ABtesting\\.venv\\Lib\\site-packages\\sklearn\\base.py:1473: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (9). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\HaruMomozu\\Desktop\\momozu\\ABtesting\\.venv\\Lib\\site-packages\\sklearn\\base.py:1473: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\HaruMomozu\\Desktop\\momozu\\ABtesting\\.venv\\Lib\\site-packages\\sklearn\\base.py:1473: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score -158.53628956913454\n",
      "temp_features (3,)\n",
      "score -74.91778197200152\n",
      "temp_features (4,)\n",
      "score 24.835621291481303\n",
      "特徴量更新\n",
      "temp_features (5,)\n",
      "score 46.67260190228143\n",
      "特徴量更新\n",
      "temp_features (6,)\n",
      "score 32.17366461968978\n",
      "temp_features (7,)\n",
      "score -1.6867527371605462\n",
      "temp_features (8,)\n",
      "score -95.86872865370295\n",
      "temp_features (9,)\n",
      "score -117.6796849527347\n",
      "temp_features (10,)\n",
      "score 15.442634929525024\n",
      "temp_features (11,)\n",
      "score 33.63291821251019\n",
      "temp_features (12,)\n",
      "score -42.22143800971725\n",
      "temp_features (13,)\n",
      "score 16.48442625985548\n",
      "temp_features (14,)\n",
      "score -6.7720467265041995\n",
      "temp_features (15,)\n",
      "score -16.50646797575743\n",
      "temp_features (16,)\n",
      "score -67.89716783079405\n",
      "num_of_features: 1 current_features: [5] , score: 46.67260190228143 best_n_clusters: 10\n",
      "temp_features (5, 0)\n",
      "score 19.80491710612988\n",
      "特徴量更新\n",
      "temp_features (5, 1)\n",
      "score 8.378800848546152\n",
      "temp_features (5, 2)\n",
      "score -161.15733297942586\n",
      "temp_features (5, 3)\n",
      "score 28.5265132450931\n",
      "特徴量更新\n",
      "temp_features (5, 4)\n",
      "score -50.30166435085626\n",
      "temp_features (5, 6)\n",
      "score -98.31049016638576\n",
      "temp_features (5, 7)\n",
      "score 22.53822231666286\n",
      "temp_features (5, 8)\n",
      "score -15.304092074032738\n",
      "temp_features (5, 9)\n",
      "score -125.50084019109886\n",
      "temp_features (5, 10)\n",
      "score 63.801617771927766\n",
      "特徴量更新\n",
      "temp_features (5, 11)\n",
      "score 19.212721811973722\n",
      "temp_features (5, 12)\n",
      "score -109.55394227113983\n",
      "temp_features (5, 13)\n",
      "score -122.01190250037052\n",
      "temp_features (5, 14)\n",
      "score -28.169804690727183\n",
      "temp_features (5, 15)\n",
      "score -29.474965358298476\n",
      "temp_features (5, 16)\n",
      "score -29.159518303228317\n",
      "num_of_features: 2 current_features: [5, 10] , score: 63.801617771927766 best_n_clusters: 9\n",
      "temp_features (5, 10, 0)\n",
      "score 65.81140235256416\n",
      "特徴量更新\n",
      "temp_features (5, 10, 1)\n",
      "score 53.055114594497574\n",
      "temp_features (5, 10, 2)\n",
      "score -65.41739351808513\n",
      "temp_features (5, 10, 3)\n",
      "score 46.303181767973015\n",
      "temp_features (5, 10, 4)\n",
      "score -69.62879243930233\n",
      "temp_features (5, 10, 6)\n",
      "score -179.37100845809505\n",
      "temp_features (5, 10, 7)\n",
      "score 17.068777881839235\n",
      "temp_features (5, 10, 8)\n",
      "score -112.0756558022276\n",
      "temp_features (5, 10, 9)\n",
      "score -87.55212235567593\n",
      "temp_features (5, 10, 11)\n",
      "score 64.66628862450968\n",
      "temp_features (5, 10, 12)\n",
      "score -4.354410818479848\n",
      "temp_features (5, 10, 13)\n",
      "score -0.26446687989842843\n",
      "temp_features (5, 10, 14)\n",
      "score -1.2312429880958264\n",
      "temp_features (5, 10, 15)\n",
      "score -72.54681580385885\n",
      "temp_features (5, 10, 16)\n",
      "score -86.2806265227806\n",
      "num_of_features: 3 current_features: [5, 10, 0] , score: 65.81140235256416 best_n_clusters: 10\n",
      "temp_features (5, 10, 0, 1)\n",
      "score 31.449328918735077\n",
      "特徴量更新\n",
      "temp_features (5, 10, 0, 2)\n",
      "score -9.549805158140101\n",
      "temp_features (5, 10, 0, 3)\n",
      "score -121.94958885497024\n",
      "temp_features (5, 10, 0, 4)\n",
      "score -40.24526604584655\n",
      "temp_features (5, 10, 0, 6)\n",
      "score 28.247343321113703\n",
      "temp_features (5, 10, 0, 7)\n",
      "score 9.715163760060852\n",
      "temp_features (5, 10, 0, 8)\n",
      "score 36.68485470656577\n",
      "特徴量更新\n",
      "temp_features (5, 10, 0, 9)\n",
      "score -6.008166122945657\n",
      "temp_features (5, 10, 0, 11)\n",
      "score -22.385247694996192\n",
      "temp_features (5, 10, 0, 12)\n",
      "score -49.580839106960894\n",
      "temp_features (5, 10, 0, 13)\n",
      "score 37.22214065319995\n",
      "特徴量更新\n",
      "temp_features (5, 10, 0, 14)\n",
      "score -101.8297440953357\n",
      "temp_features (5, 10, 0, 15)\n",
      "score 14.814361806398235\n",
      "temp_features (5, 10, 0, 16)\n",
      "score -149.82862849275006\n",
      "num_of_features: 4 current_features: [5, 10, 0, 13] , score: 37.22214065319995 best_n_clusters: 10\n",
      "temp_features (5, 10, 0, 13, 1)\n",
      "score 5.480328386709243\n",
      "特徴量更新\n",
      "temp_features (5, 10, 0, 13, 2)\n",
      "score 49.76114815848124\n",
      "特徴量更新\n",
      "temp_features (5, 10, 0, 13, 3)\n",
      "score -89.87887699779753\n",
      "temp_features (5, 10, 0, 13, 4)\n",
      "score -187.0763165522442\n",
      "temp_features (5, 10, 0, 13, 6)\n",
      "score -24.474057773241498\n",
      "temp_features (5, 10, 0, 13, 7)\n",
      "score -27.390898039663636\n",
      "temp_features (5, 10, 0, 13, 8)\n",
      "score -29.190230819804654\n",
      "temp_features (5, 10, 0, 13, 9)\n",
      "score -75.44372887543969\n",
      "temp_features (5, 10, 0, 13, 11)\n",
      "score -26.08633336457786\n",
      "temp_features (5, 10, 0, 13, 12)\n",
      "score 65.97565680286588\n",
      "特徴量更新\n",
      "temp_features (5, 10, 0, 13, 14)\n",
      "score -34.650941836328954\n",
      "temp_features (5, 10, 0, 13, 15)\n",
      "score -4.3209845337012665\n",
      "temp_features (5, 10, 0, 13, 16)\n",
      "score -24.32307931975235\n",
      "num_of_features: 5 current_features: [5, 10, 0, 13, 12] , score: 65.97565680286588 best_n_clusters: 10\n",
      "temp_features (5, 10, 0, 13, 12, 1)\n",
      "score -94.56244114787968\n",
      "特徴量更新\n",
      "temp_features (5, 10, 0, 13, 12, 2)\n",
      "score 24.804017235671804\n",
      "特徴量更新\n",
      "temp_features (5, 10, 0, 13, 12, 3)\n",
      "score 59.718339202420324\n",
      "特徴量更新\n",
      "temp_features (5, 10, 0, 13, 12, 4)\n",
      "score -99.91393367526773\n",
      "temp_features (5, 10, 0, 13, 12, 6)\n",
      "score -252.30952443226178\n",
      "temp_features (5, 10, 0, 13, 12, 7)\n",
      "score -6.686203603174912\n",
      "temp_features (5, 10, 0, 13, 12, 8)\n",
      "score -154.0385387682079\n",
      "temp_features (5, 10, 0, 13, 12, 9)\n",
      "score 19.0149172329124\n",
      "temp_features (5, 10, 0, 13, 12, 11)\n",
      "score -78.90023448728141\n",
      "temp_features (5, 10, 0, 13, 12, 14)\n",
      "score -87.50414140668335\n",
      "temp_features (5, 10, 0, 13, 12, 15)\n",
      "score -34.21041709683843\n",
      "temp_features (5, 10, 0, 13, 12, 16)\n",
      "score -123.07499580688793\n",
      "num_of_features: 6 current_features: [5, 10, 0, 13, 12, 3] , score: 59.718339202420324 best_n_clusters: 10\n",
      "temp_features (5, 10, 0, 13, 12, 3, 1)\n",
      "score -29.53895370857582\n",
      "特徴量更新\n",
      "temp_features (5, 10, 0, 13, 12, 3, 2)\n",
      "score -145.57050829658138\n",
      "temp_features (5, 10, 0, 13, 12, 3, 4)\n",
      "score 8.412139363781678\n",
      "特徴量更新\n",
      "temp_features (5, 10, 0, 13, 12, 3, 6)\n",
      "score 3.0658869237953246\n",
      "temp_features (5, 10, 0, 13, 12, 3, 7)\n",
      "score -28.885357116857293\n",
      "temp_features (5, 10, 0, 13, 12, 3, 8)\n",
      "score 23.22621959831285\n",
      "特徴量更新\n",
      "temp_features (5, 10, 0, 13, 12, 3, 9)\n",
      "score -257.21552782384816\n",
      "temp_features (5, 10, 0, 13, 12, 3, 11)\n",
      "score -17.966531699304245\n",
      "temp_features (5, 10, 0, 13, 12, 3, 14)\n",
      "score 23.289936276805545\n",
      "特徴量更新\n",
      "temp_features (5, 10, 0, 13, 12, 3, 15)\n",
      "score -210.3637493894079\n",
      "temp_features (5, 10, 0, 13, 12, 3, 16)\n",
      "score 12.1459157935762\n",
      "num_of_features: 7 current_features: [5, 10, 0, 13, 12, 3, 14] , score: 23.289936276805545 best_n_clusters: 10\n",
      "temp_features (5, 10, 0, 13, 12, 3, 14, 1)\n",
      "score -2.757788323413868\n",
      "特徴量更新\n",
      "temp_features (5, 10, 0, 13, 12, 3, 14, 2)\n",
      "score -150.43064072380184\n",
      "temp_features (5, 10, 0, 13, 12, 3, 14, 4)\n",
      "score -152.3773276065453\n",
      "temp_features (5, 10, 0, 13, 12, 3, 14, 6)\n",
      "score -4.765862995580017\n",
      "temp_features (5, 10, 0, 13, 12, 3, 14, 7)\n",
      "score -46.92821369630793\n",
      "temp_features (5, 10, 0, 13, 12, 3, 14, 8)\n",
      "score 38.2340199055501\n",
      "特徴量更新\n",
      "temp_features (5, 10, 0, 13, 12, 3, 14, 9)\n",
      "score 18.10213478156244\n",
      "temp_features (5, 10, 0, 13, 12, 3, 14, 11)\n",
      "score 62.00818001840862\n",
      "特徴量更新\n",
      "temp_features (5, 10, 0, 13, 12, 3, 14, 15)\n",
      "score -0.9413170977551566\n",
      "temp_features (5, 10, 0, 13, 12, 3, 14, 16)\n",
      "score -7.682853611428553\n",
      "num_of_features: 8 current_features: [5, 10, 0, 13, 12, 3, 14, 11] , score: 62.00818001840862 best_n_clusters: 10\n",
      "temp_features (5, 10, 0, 13, 12, 3, 14, 11, 1)\n",
      "score -26.78162172586065\n",
      "特徴量更新\n",
      "temp_features (5, 10, 0, 13, 12, 3, 14, 11, 2)\n",
      "score -14.099783001311383\n",
      "特徴量更新\n",
      "temp_features (5, 10, 0, 13, 12, 3, 14, 11, 4)\n",
      "score 6.0609900450485865\n",
      "特徴量更新\n",
      "temp_features (5, 10, 0, 13, 12, 3, 14, 11, 6)\n",
      "score 1.7348637108942966\n",
      "temp_features (5, 10, 0, 13, 12, 3, 14, 11, 7)\n",
      "score -33.023992021643835\n",
      "temp_features (5, 10, 0, 13, 12, 3, 14, 11, 8)\n",
      "score -93.98291503729376\n",
      "temp_features (5, 10, 0, 13, 12, 3, 14, 11, 9)\n",
      "score 18.627190288378216\n",
      "特徴量更新\n",
      "temp_features (5, 10, 0, 13, 12, 3, 14, 11, 15)\n",
      "score 47.01482823384959\n",
      "特徴量更新\n",
      "temp_features (5, 10, 0, 13, 12, 3, 14, 11, 16)\n",
      "score -149.41641155400788\n",
      "num_of_features: 9 current_features: [5, 10, 0, 13, 12, 3, 14, 11, 15] , score: 47.01482823384959 best_n_clusters: 9\n",
      "temp_features (5, 10, 0, 13, 12, 3, 14, 11, 15, 1)\n",
      "score 63.10379563752993\n",
      "特徴量更新\n",
      "temp_features (5, 10, 0, 13, 12, 3, 14, 11, 15, 2)\n",
      "score -108.14605262813627\n",
      "temp_features (5, 10, 0, 13, 12, 3, 14, 11, 15, 4)\n",
      "score 22.904615158116258\n",
      "temp_features (5, 10, 0, 13, 12, 3, 14, 11, 15, 6)\n",
      "score 47.69026141497399\n",
      "temp_features (5, 10, 0, 13, 12, 3, 14, 11, 15, 7)\n",
      "score 3.9091362629441018\n",
      "temp_features (5, 10, 0, 13, 12, 3, 14, 11, 15, 8)\n",
      "score -112.89036623363376\n",
      "temp_features (5, 10, 0, 13, 12, 3, 14, 11, 15, 9)\n",
      "score -64.08453915611818\n",
      "temp_features (5, 10, 0, 13, 12, 3, 14, 11, 15, 16)\n",
      "score -56.248539253372364\n",
      "num_of_features: 10 current_features: [5, 10, 0, 13, 12, 3, 14, 11, 15, 1] , score: 63.10379563752993 best_n_clusters: 10\n",
      "[ PostStratification ]\n",
      "temp_features (0,)\n",
      "score -100.09706662788918\n",
      "特徴量更新\n",
      "temp_features (1,)\n",
      "score 26.7092731306552\n",
      "特徴量更新\n",
      "temp_features (2,)\n",
      "score -7.074805517401361\n",
      "temp_features (3,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HaruMomozu\\Desktop\\momozu\\ABtesting\\.venv\\Lib\\site-packages\\sklearn\\base.py:1473: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (3). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\HaruMomozu\\Desktop\\momozu\\ABtesting\\.venv\\Lib\\site-packages\\sklearn\\base.py:1473: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\HaruMomozu\\Desktop\\momozu\\ABtesting\\.venv\\Lib\\site-packages\\sklearn\\base.py:1473: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\HaruMomozu\\Desktop\\momozu\\ABtesting\\.venv\\Lib\\site-packages\\sklearn\\base.py:1473: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (6). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\HaruMomozu\\Desktop\\momozu\\ABtesting\\.venv\\Lib\\site-packages\\sklearn\\base.py:1473: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\HaruMomozu\\Desktop\\momozu\\ABtesting\\.venv\\Lib\\site-packages\\sklearn\\base.py:1473: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\HaruMomozu\\Desktop\\momozu\\ABtesting\\.venv\\Lib\\site-packages\\sklearn\\base.py:1473: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (9). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\HaruMomozu\\Desktop\\momozu\\ABtesting\\.venv\\Lib\\site-packages\\sklearn\\base.py:1473: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\HaruMomozu\\Desktop\\momozu\\ABtesting\\.venv\\Lib\\site-packages\\sklearn\\base.py:1473: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score -50.46982145695213\n",
      "temp_features (4,)\n",
      "score -144.12283201998082\n",
      "temp_features (5,)\n",
      "score 45.482520636448996\n",
      "特徴量更新\n",
      "temp_features (6,)\n",
      "score 26.59163105593505\n",
      "temp_features (7,)\n",
      "score -33.88720798731983\n",
      "temp_features (8,)\n",
      "score -20.545931496846404\n",
      "temp_features (9,)\n",
      "score -48.49537605810876\n",
      "temp_features (10,)\n",
      "score 15.035040099269793\n",
      "temp_features (11,)\n",
      "score -246.19230872737413\n",
      "temp_features (12,)\n",
      "score -45.33116971377995\n",
      "temp_features (13,)\n",
      "score -177.61448112171462\n",
      "temp_features (14,)\n",
      "score -229.16970381907652\n",
      "temp_features (15,)\n",
      "score -3.087769176612798\n",
      "temp_features (16,)\n",
      "score 20.909886694678846\n",
      "num_of_features: 1 current_features: [5] , score: 45.482520636448996 best_n_clusters: 10\n",
      "temp_features (5, 0)\n",
      "score -102.8475746328131\n",
      "特徴量更新\n",
      "temp_features (5, 1)\n",
      "score 61.84752117755301\n",
      "特徴量更新\n",
      "temp_features (5, 2)\n",
      "score -158.78545071748698\n",
      "temp_features (5, 3)\n",
      "score -24.17064704067604\n",
      "temp_features (5, 4)\n",
      "score 5.297639214972561\n",
      "temp_features (5, 6)\n",
      "score -233.43367844383928\n",
      "temp_features (5, 7)\n",
      "score -97.2255492481668\n",
      "temp_features (5, 8)\n",
      "score 25.55582389530865\n",
      "temp_features (5, 9)\n",
      "score -17.524112222340694\n",
      "temp_features (5, 10)\n",
      "score 46.061788479709534\n",
      "temp_features (5, 11)\n",
      "score -93.40421917407065\n",
      "temp_features (5, 12)\n",
      "score -10.137914440026119\n",
      "temp_features (5, 13)\n",
      "score 53.861246313275316\n",
      "temp_features (5, 14)\n",
      "score -6.813321673694728\n",
      "temp_features (5, 15)\n",
      "score 28.38602226819411\n",
      "temp_features (5, 16)\n",
      "score -15.66866399760718\n",
      "num_of_features: 2 current_features: [5, 1] , score: 61.84752117755301 best_n_clusters: 10\n",
      "temp_features (5, 1, 0)\n",
      "score -51.1394215265264\n",
      "特徴量更新\n",
      "temp_features (5, 1, 2)\n",
      "score 13.850201615826307\n",
      "特徴量更新\n",
      "temp_features (5, 1, 3)\n",
      "score -33.48661830372861\n",
      "temp_features (5, 1, 4)\n",
      "score -22.08931870568176\n",
      "temp_features (5, 1, 6)\n",
      "score -6.649619706099696\n",
      "temp_features (5, 1, 7)\n",
      "score 44.30928856734242\n",
      "特徴量更新\n",
      "temp_features (5, 1, 8)\n",
      "score 57.507785044967704\n",
      "特徴量更新\n",
      "temp_features (5, 1, 9)\n",
      "score 24.944043000693974\n",
      "temp_features (5, 1, 10)\n",
      "score 29.264538982314704\n",
      "temp_features (5, 1, 11)\n",
      "score -23.859302851220534\n",
      "temp_features (5, 1, 12)\n",
      "score 44.27451285764909\n",
      "temp_features (5, 1, 13)\n",
      "score -203.58871658457082\n",
      "temp_features (5, 1, 14)\n",
      "score 6.633259251470669\n",
      "temp_features (5, 1, 15)\n",
      "score -102.31442695339106\n",
      "temp_features (5, 1, 16)\n",
      "score -117.0134716920622\n",
      "num_of_features: 3 current_features: [5, 1, 8] , score: 57.507785044967704 best_n_clusters: 9\n",
      "temp_features (5, 1, 8, 0)\n",
      "score -73.11024957693273\n",
      "特徴量更新\n",
      "temp_features (5, 1, 8, 2)\n",
      "score 12.055395774459953\n",
      "特徴量更新\n",
      "temp_features (5, 1, 8, 3)\n",
      "score 49.13947684486194\n",
      "特徴量更新\n",
      "temp_features (5, 1, 8, 4)\n",
      "score -39.425270920934\n",
      "temp_features (5, 1, 8, 6)\n",
      "score 18.379161549121704\n",
      "temp_features (5, 1, 8, 7)\n",
      "score -13.591360592832924\n",
      "temp_features (5, 1, 8, 9)\n",
      "score 0.8819973559744732\n",
      "temp_features (5, 1, 8, 10)\n",
      "score 9.711617025637842\n",
      "temp_features (5, 1, 8, 11)\n",
      "score -17.59022942788766\n",
      "temp_features (5, 1, 8, 12)\n",
      "score -65.76881934035441\n",
      "temp_features (5, 1, 8, 13)\n",
      "score 26.567001920976974\n",
      "temp_features (5, 1, 8, 14)\n",
      "score -261.70254156074674\n",
      "temp_features (5, 1, 8, 15)\n",
      "score 27.770260026630787\n",
      "temp_features (5, 1, 8, 16)\n",
      "score 11.347107475098406\n",
      "num_of_features: 4 current_features: [5, 1, 8, 3] , score: 49.13947684486194 best_n_clusters: 9\n",
      "temp_features (5, 1, 8, 3, 0)\n",
      "score 42.70872568136752\n",
      "特徴量更新\n",
      "temp_features (5, 1, 8, 3, 2)\n",
      "score 43.30289187799161\n",
      "特徴量更新\n",
      "temp_features (5, 1, 8, 3, 4)\n",
      "score 26.39942747823245\n",
      "temp_features (5, 1, 8, 3, 6)\n",
      "score -45.297050957201805\n",
      "temp_features (5, 1, 8, 3, 7)\n",
      "score 61.5289514985242\n",
      "特徴量更新\n",
      "temp_features (5, 1, 8, 3, 9)\n",
      "score -35.04325050410344\n",
      "temp_features (5, 1, 8, 3, 10)\n",
      "score -43.954945510361895\n",
      "temp_features (5, 1, 8, 3, 11)\n",
      "score -50.86779309121417\n",
      "temp_features (5, 1, 8, 3, 12)\n",
      "score 22.829115947914524\n",
      "temp_features (5, 1, 8, 3, 13)\n",
      "score -100.83305319587588\n",
      "temp_features (5, 1, 8, 3, 14)\n",
      "score 67.4899431079796\n",
      "特徴量更新\n",
      "temp_features (5, 1, 8, 3, 15)\n",
      "score -47.66305291991833\n",
      "temp_features (5, 1, 8, 3, 16)\n",
      "score 64.02776032073878\n",
      "num_of_features: 5 current_features: [5, 1, 8, 3, 14] , score: 67.4899431079796 best_n_clusters: 10\n",
      "temp_features (5, 1, 8, 3, 14, 0)\n",
      "score -31.31446768989903\n",
      "特徴量更新\n",
      "temp_features (5, 1, 8, 3, 14, 2)\n",
      "score 31.482605420737485\n",
      "特徴量更新\n",
      "temp_features (5, 1, 8, 3, 14, 4)\n",
      "score 26.903600537007943\n",
      "temp_features (5, 1, 8, 3, 14, 6)\n",
      "score -146.02779854481614\n",
      "temp_features (5, 1, 8, 3, 14, 7)\n",
      "score -19.318966634618274\n",
      "temp_features (5, 1, 8, 3, 14, 9)\n",
      "score -113.54306124409028\n",
      "temp_features (5, 1, 8, 3, 14, 10)\n",
      "score -60.60369685187852\n",
      "temp_features (5, 1, 8, 3, 14, 11)\n",
      "score 6.067167163100818\n",
      "temp_features (5, 1, 8, 3, 14, 12)\n",
      "score -27.282189006349334\n",
      "temp_features (5, 1, 8, 3, 14, 13)\n",
      "score 55.05363563598789\n",
      "特徴量更新\n",
      "temp_features (5, 1, 8, 3, 14, 15)\n",
      "score -116.32133843589831\n",
      "temp_features (5, 1, 8, 3, 14, 16)\n",
      "score -29.452745626288678\n",
      "num_of_features: 6 current_features: [5, 1, 8, 3, 14, 13] , score: 55.05363563598789 best_n_clusters: 10\n",
      "temp_features (5, 1, 8, 3, 14, 13, 0)\n",
      "score -1.3223995450103887\n",
      "特徴量更新\n",
      "temp_features (5, 1, 8, 3, 14, 13, 2)\n",
      "score -13.981858431161086\n",
      "temp_features (5, 1, 8, 3, 14, 13, 4)\n",
      "score -90.01753938624626\n",
      "temp_features (5, 1, 8, 3, 14, 13, 6)\n",
      "score -105.55746089393114\n",
      "temp_features (5, 1, 8, 3, 14, 13, 7)\n",
      "score -89.92423751916428\n",
      "temp_features (5, 1, 8, 3, 14, 13, 9)\n",
      "score 13.783550944031585\n",
      "特徴量更新\n",
      "temp_features (5, 1, 8, 3, 14, 13, 10)\n",
      "score 37.375616961692614\n",
      "特徴量更新\n",
      "temp_features (5, 1, 8, 3, 14, 13, 11)\n",
      "score 42.93010536820415\n",
      "特徴量更新\n",
      "temp_features (5, 1, 8, 3, 14, 13, 12)\n",
      "score 42.848853263459354\n",
      "temp_features (5, 1, 8, 3, 14, 13, 15)\n",
      "score 56.17834461839648\n",
      "特徴量更新\n",
      "temp_features (5, 1, 8, 3, 14, 13, 16)\n",
      "score -27.82851134919455\n",
      "num_of_features: 7 current_features: [5, 1, 8, 3, 14, 13, 15] , score: 56.17834461839648 best_n_clusters: 9\n",
      "temp_features (5, 1, 8, 3, 14, 13, 15, 0)\n",
      "score -29.12020908159869\n",
      "特徴量更新\n",
      "temp_features (5, 1, 8, 3, 14, 13, 15, 2)\n",
      "score -14.408307313874147\n",
      "特徴量更新\n",
      "temp_features (5, 1, 8, 3, 14, 13, 15, 4)\n",
      "score 29.54549472411744\n",
      "特徴量更新\n",
      "temp_features (5, 1, 8, 3, 14, 13, 15, 6)\n",
      "score 18.58898277818136\n",
      "temp_features (5, 1, 8, 3, 14, 13, 15, 7)\n",
      "score -41.13911355480357\n",
      "temp_features (5, 1, 8, 3, 14, 13, 15, 9)\n",
      "score -2.105144762359301\n",
      "temp_features (5, 1, 8, 3, 14, 13, 15, 10)\n",
      "score 64.83939550537956\n",
      "特徴量更新\n",
      "temp_features (5, 1, 8, 3, 14, 13, 15, 11)\n",
      "score -103.70607053751475\n",
      "temp_features (5, 1, 8, 3, 14, 13, 15, 12)\n",
      "score 27.049023187566124\n",
      "temp_features (5, 1, 8, 3, 14, 13, 15, 16)\n",
      "score -13.969099082102222\n",
      "num_of_features: 8 current_features: [5, 1, 8, 3, 14, 13, 15, 10] , score: 64.83939550537956 best_n_clusters: 10\n",
      "temp_features (5, 1, 8, 3, 14, 13, 15, 10, 0)\n",
      "score 7.063424592402445\n",
      "特徴量更新\n",
      "temp_features (5, 1, 8, 3, 14, 13, 15, 10, 2)\n",
      "score 3.828749695568723\n",
      "temp_features (5, 1, 8, 3, 14, 13, 15, 10, 4)\n",
      "score 20.188313576933204\n",
      "特徴量更新\n",
      "temp_features (5, 1, 8, 3, 14, 13, 15, 10, 6)\n",
      "score 41.69206647280531\n",
      "特徴量更新\n",
      "temp_features (5, 1, 8, 3, 14, 13, 15, 10, 7)\n",
      "score 24.04869290734142\n",
      "temp_features (5, 1, 8, 3, 14, 13, 15, 10, 9)\n",
      "score -16.24457086296671\n",
      "temp_features (5, 1, 8, 3, 14, 13, 15, 10, 11)\n",
      "score 23.896065052190895\n",
      "temp_features (5, 1, 8, 3, 14, 13, 15, 10, 12)\n",
      "score -102.85963277418091\n",
      "temp_features (5, 1, 8, 3, 14, 13, 15, 10, 16)\n",
      "score -12.913874488362055\n",
      "num_of_features: 9 current_features: [5, 1, 8, 3, 14, 13, 15, 10, 6] , score: 41.69206647280531 best_n_clusters: 9\n",
      "temp_features (5, 1, 8, 3, 14, 13, 15, 10, 6, 0)\n",
      "score 53.07711848799927\n",
      "特徴量更新\n",
      "temp_features (5, 1, 8, 3, 14, 13, 15, 10, 6, 2)\n",
      "score -29.390281048906154\n",
      "temp_features (5, 1, 8, 3, 14, 13, 15, 10, 6, 4)\n",
      "score 71.25062169641731\n",
      "特徴量更新\n",
      "temp_features (5, 1, 8, 3, 14, 13, 15, 10, 6, 7)\n",
      "score 10.58584947111314\n",
      "temp_features (5, 1, 8, 3, 14, 13, 15, 10, 6, 9)\n",
      "score 22.87843539289036\n",
      "temp_features (5, 1, 8, 3, 14, 13, 15, 10, 6, 11)\n",
      "score 22.512681135947755\n",
      "temp_features (5, 1, 8, 3, 14, 13, 15, 10, 6, 12)\n",
      "score 38.905278262654306\n",
      "temp_features (5, 1, 8, 3, 14, 13, 15, 10, 6, 16)\n",
      "score -31.20424662707817\n",
      "num_of_features: 10 current_features: [5, 1, 8, 3, 14, 13, 15, 10, 6, 4] , score: 71.25062169641731 best_n_clusters: 9\n",
      "[ OptimalAllocation ]\n",
      "temp_features (0,)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (10,) (2,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 13\u001b[0m\n\u001b[0;32m      1\u001b[0m ins \u001b[38;5;241m=\u001b[39m Allocation_in_Wrapper(\n\u001b[0;32m      2\u001b[0m     maximum_features_to_select\u001b[38;5;241m=\u001b[39mMAXIMUM_FEATURES_TO_SELECT,\n\u001b[0;32m      3\u001b[0m     n_clusters\u001b[38;5;241m=\u001b[39mN_CLUSTERS,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     10\u001b[0m     selecting_features\u001b[38;5;241m=\u001b[39mSELECTING_FEATURES,\n\u001b[0;32m     11\u001b[0m )\n\u001b[1;32m---> 13\u001b[0m \u001b[43mins\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_scaled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m selected_features_index \u001b[38;5;241m=\u001b[39m ins\u001b[38;5;241m.\u001b[39mget_feature_index_out()\n\u001b[0;32m     15\u001b[0m cluster_label \u001b[38;5;241m=\u001b[39m ins\u001b[38;5;241m.\u001b[39mget_final_cluster_assignments()\n",
      "Cell \u001b[1;32mIn[6], line 68\u001b[0m, in \u001b[0;36mAllocation_in_Wrapper.fss\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m     64\u001b[0m temp_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(\n\u001b[0;32m     65\u001b[0m     current_features \u001b[38;5;241m+\u001b[39m [feature]\n\u001b[0;32m     66\u001b[0m )  \u001b[38;5;66;03m# 特徴量をひとつ加え、score計算    ###########ここまでok\u001b[39;00m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtemp_features\u001b[39m\u001b[38;5;124m\"\u001b[39m, temp_features)\n\u001b[1;32m---> 68\u001b[0m score, labels, n_clusters \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcrit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     69\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemp_features\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallocation_method\u001b[49m\n\u001b[0;32m     70\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscore\u001b[39m\u001b[38;5;124m\"\u001b[39m, score)\n\u001b[0;32m     72\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m score \u001b[38;5;241m>\u001b[39m best_score:\n",
      "Cell \u001b[1;32mIn[6], line 138\u001b[0m, in \u001b[0;36mAllocation_in_Wrapper.crit\u001b[1;34m(self, X, y, allocation_method)\u001b[0m\n\u001b[0;32m    135\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mN_cluster_size \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mbincount(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mN_cluster_label)\n\u001b[0;32m    137\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m--> 138\u001b[0m error_variance_reduction_rate \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcauculate_reduction_rate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    139\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallocation_method\u001b[49m\n\u001b[0;32m    140\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    141\u001b[0m score \u001b[38;5;241m=\u001b[39m error_variance_reduction_rate\n\u001b[0;32m    142\u001b[0m labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mN_cluster_label\n",
      "Cell \u001b[1;32mIn[6], line 191\u001b[0m, in \u001b[0;36mAllocation_in_Wrapper.cauculate_reduction_rate\u001b[1;34m(self, X, y, allocation_method)\u001b[0m\n\u001b[0;32m    189\u001b[0m         y_hat \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimate_y_mean_post(X, y)\n\u001b[0;32m    190\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 191\u001b[0m         y_hat \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimate_y_mean_other\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallocation_method\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    192\u001b[0m     y_hats\u001b[38;5;241m.\u001b[39mappend(\n\u001b[0;32m    193\u001b[0m         {\n\u001b[0;32m    194\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpolicy\u001b[39m\u001b[38;5;124m\"\u001b[39m: allocation_method,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    197\u001b[0m         }\n\u001b[0;32m    198\u001b[0m     )\n\u001b[0;32m    200\u001b[0m y_hat_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(y_hats)\n",
      "Cell \u001b[1;32mIn[6], line 252\u001b[0m, in \u001b[0;36mAllocation_in_Wrapper.estimate_y_mean_other\u001b[1;34m(self, X, y, allocation_method)\u001b[0m\n\u001b[0;32m    250\u001b[0m     n_cluster_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mProportionalAllocation(X, y)\n\u001b[0;32m    251\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m allocation_method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOptimalAllocation\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 252\u001b[0m     n_cluster_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mOptimalAllocation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    254\u001b[0m weights \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mN_cluster_size \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mN_cluster_size\u001b[38;5;241m.\u001b[39msum()\n\u001b[0;32m    255\u001b[0m y_hat \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "Cell \u001b[1;32mIn[6], line 303\u001b[0m, in \u001b[0;36mAllocation_in_Wrapper.OptimalAllocation\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    299\u001b[0m \u001b[38;5;66;03m# S:クラスタ毎の目的変数のvarianceを要素とする配列 (H, )\u001b[39;00m\n\u001b[0;32m    300\u001b[0m S \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(\n\u001b[0;32m    301\u001b[0m     [np\u001b[38;5;241m.\u001b[39mvar(y[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mN_cluster_label \u001b[38;5;241m==\u001b[39m h]) \u001b[38;5;28;01mfor\u001b[39;00m h \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_clusters)]\n\u001b[0;32m    302\u001b[0m )\n\u001b[1;32m--> 303\u001b[0m d \u001b[38;5;241m=\u001b[39m \u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mN_cluster_size\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mS\u001b[49m\n\u001b[0;32m    305\u001b[0m n_cluster_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mm\u001b[38;5;241m.\u001b[39mcopy()  \u001b[38;5;66;03m# 初期値\u001b[39;00m\n\u001b[0;32m    307\u001b[0m M \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mM\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mM \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mN_cluster_size\u001b[38;5;241m.\u001b[39mcopy()\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (10,) (2,) "
     ]
    }
   ],
   "source": [
    "ins = Allocation_in_Wrapper(\n",
    "    maximum_features_to_select=MAXIMUM_FEATURES_TO_SELECT,\n",
    "    n_clusters=N_CLUSTERS,\n",
    "    clustering_method=CLUSTERING_METHOD,\n",
    "    allocation_methods=ALLOCATION_METHODS,\n",
    "    sample_size=SAMPLE_SIZE,\n",
    "    n_trials=N_TRIALS,\n",
    "    m_value=m_VALUE,\n",
    "    random_state=RANDOM_STATE,\n",
    "    selecting_features=SELECTING_FEATURES,\n",
    ")\n",
    "\n",
    "ins.fss(X_scaled, y)\n",
    "selected_features_index = ins.get_feature_index_out()\n",
    "cluster_label = ins.get_final_cluster_assignments()\n",
    "cluster_size = np.unique(cluster_label, return_counts=True)[1]\n",
    "features_score_dict = ins.get_features_score()\n",
    "print(features_score_dict)\n",
    "\n",
    "for allocation, dict in features_score_dict.items():\n",
    "    plt.bar(dict.keys(), dict.values())\n",
    "    for key, value in dict.items():\n",
    "        rounded_value = round(value, 2)\n",
    "        plt.text(key, value + 0.3, str(rounded_value), ha=\"center\")\n",
    "    plt.title(f\"evaluation score({allocation})\")\n",
    "    plt.xlabel(\"number of features\")\n",
    "    plt.ylabel(\"evaluation value\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

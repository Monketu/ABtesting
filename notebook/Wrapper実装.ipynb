{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils.validation import check_array, check_X_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      RIDAGEYR  RIAGENDR  PAQ605  BMXBMI  LBXGLU  DIQ010  LBXGLT  LBXIN\n",
      "0         61.0       2.0     2.0    35.7   110.0     2.0   150.0  14.91\n",
      "1         26.0       2.0     2.0    20.3    89.0     2.0    80.0   3.85\n",
      "2         16.0       1.0     2.0    23.2    89.0     2.0    68.0   6.14\n",
      "3         32.0       1.0     2.0    28.9   104.0     2.0    84.0  16.15\n",
      "4         38.0       2.0     1.0    35.9   103.0     2.0    81.0  10.92\n",
      "...        ...       ...     ...     ...     ...     ...     ...    ...\n",
      "2165      38.0       2.0     2.0    33.5   100.0     2.0    73.0   6.53\n",
      "2166      61.0       1.0     2.0    30.0    93.0     2.0   208.0  13.02\n",
      "2167      34.0       1.0     2.0    23.7   103.0     2.0   124.0  21.41\n",
      "2168      60.0       2.0     2.0    27.4    90.0     2.0   108.0   4.99\n",
      "2169      26.0       1.0     2.0    24.5   108.0     2.0   108.0   3.76\n",
      "\n",
      "[2170 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "df = pd.read_csv(\n",
    "    R\"C:\\Users\\HaruMomozu\\Documents\\オンラインデータ\\NHANES_age_prediction.csv\"\n",
    ")\n",
    "df = df.drop(columns=[\"SEQN\", \"age_group\"])\n",
    "\n",
    "obj = \"BMXBMI\"\n",
    "features_list = [\n",
    "    \"RIDAGEYR\",  # 年齢（連続変数）\n",
    "    \"RIAGENDR\",  # 性別（1:Male, 2:Female)\n",
    "    \"PAQ605\",  # 運動有無(1:日常的に運動する, 2:運動しない)\n",
    "    \"LBXGLU\",  # 断食後の血糖値（連続変数）\n",
    "    \"DIQ010\",  # 糖尿病の有無(0:なし、1:あり)\n",
    "    \"LBXGLT\",  # 口内の健康状態（連続変数）\n",
    "    \"LBXIN\",  # 血中インスリン濃度（連続変数）\n",
    "]\n",
    "\n",
    "\n",
    "# 外れ値の除去\n",
    "def remove_outliers_zscore(data, metric, threshold=2):\n",
    "    z_scores = np.abs(stats.zscore(data[metric]))\n",
    "    data = data[(z_scores < threshold)]\n",
    "    return data\n",
    "\n",
    "\n",
    "df = remove_outliers_zscore(df, obj)\n",
    "\n",
    "# process_features\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "X = df[features_list]\n",
    "# 数値列の標準化\n",
    "scaler = StandardScaler()\n",
    "scaled_features = scaler.fit_transform(X)\n",
    "\n",
    "X_scaled = pd.DataFrame(scaled_features, columns=features_list)\n",
    "y = df[obj]  # 目的変数\n",
    "\n",
    "# 行を詰める\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.utils import check_X_y, check_array\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class Wrapper(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, n_features_to_select):\n",
    "        self.n_features_to_select = n_features_to_select  # 選択する特徴量の数\n",
    "\n",
    "    def FSSEM(self, X, y):\n",
    "        X, y = check_X_y(X, y)  # データの整合性確認\n",
    "\n",
    "        self.n_features_ = X.shape[1]  # 特徴量の総数\n",
    "        self.selected_features_ = []  # 特徴量サブセット初期化\n",
    "\n",
    "        # 現在選択されている特徴量のインデックスを格納する用\n",
    "        current_features = []\n",
    "        # 選択されていない特徴量のインデックスを格納する用\n",
    "        remaining_features = list(range(X.shape[1]))\n",
    "\n",
    "        # SFS\n",
    "        while len(current_features) < self.n_features_to_select:\n",
    "            best_score = -np.inf  # 最良スコアの初期化（マイナス無限大）\n",
    "            best_feature = None\n",
    "\n",
    "            # 追加すべき特徴量を1つ決める\n",
    "            for feature in remaining_features:\n",
    "                temp_features = current_features + [\n",
    "                    feature\n",
    "                ]  # 現在の特徴量リストに新しい特徴量を加えた仮のリストを作成\n",
    "                score = self.evaluate_subset(\n",
    "                    X[:, temp_features], y\n",
    "                )  # 仮のリストに基づいて評価\n",
    "                if score > best_score:  # 評価スコアが最良スコアよりも大きいときは更新\n",
    "                    print(score)\n",
    "                    best_score = score\n",
    "                    best_feature = feature\n",
    "\n",
    "            # current_featuresとremaining_featuresの更新\n",
    "            if best_feature is not None:\n",
    "                current_features.append(best_feature)\n",
    "                remaining_features.remove(best_feature)\n",
    "                self.selected_features_ = current_features\n",
    "            else:\n",
    "                break\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        check_array(X)  # Xを検証\n",
    "        return X[:, self.selected_features_]  # 選択された特徴量だけを抽出して返す\n",
    "\n",
    "    def evaluate_subset(self, X_subset, y):  # EMクラスタリング\n",
    "        n_clusters = 3\n",
    "\n",
    "        gmm = GaussianMixture(n_components=n_clusters)\n",
    "        gmm.fit(X_subset)\n",
    "\n",
    "        # GMMのパラメータ\n",
    "        means = gmm.means_  # 各クラスタの平均ベクトル\n",
    "        covariances = gmm.covariances_  # 各クラスタの共分散行列\n",
    "        weights = gmm.weights_  # 各クラスタの混合係数\n",
    "        overall_mean = np.sum(\n",
    "            [weights[k] * means[k] for k in range(n_clusters)], axis=0\n",
    "        )\n",
    "        # クラスタ内分離行列\n",
    "        S_W = np.sum([weights[k] * covariances[k] for k in range(n_clusters)], axis=0)\n",
    "\n",
    "        # クラスタ間分離行列\n",
    "        S_B = np.sum(\n",
    "            [\n",
    "                weights[k] * np.outer(means[k] - overall_mean, means[k] - overall_mean)\n",
    "                for k in range(n_clusters)\n",
    "            ],\n",
    "            axis=0,\n",
    "        )\n",
    "\n",
    "        # 散乱分離性\n",
    "        scatter_discriminability = np.trace(np.linalg.inv(S_W).dot(S_B))\n",
    "        return scatter_discriminability\n",
    "\n",
    "    def get_feature_index_out(self):\n",
    "        # 選択された特徴量のインデックスを返す\n",
    "        return np.array(self.selected_features_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.utils import check_X_y, check_array\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class Wrapper(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, n_features_to_select, n_clusters=3, random_state=None):\n",
    "        self.n_features_to_select = n_features_to_select  # 選択する特徴量の数\n",
    "        self.n_clusters = n_clusters  # クラスタ数\n",
    "        self.random_state = random_state  # 乱数シード\n",
    "\n",
    "    def FSSEM(self, X, y):\n",
    "        X, y = check_X_y(X, y)  # データの整合性確認\n",
    "\n",
    "        self.n_features_ = X.shape[1]  # 特徴量の総数\n",
    "        self.selected_features_ = []  # 特徴量サブセット初期化\n",
    "\n",
    "        # 現在選択されている特徴量のインデックスを格納する用\n",
    "        current_features = []\n",
    "        # 選択されていない特徴量のインデックスを格納する用\n",
    "        remaining_features = list(range(X.shape[1]))\n",
    "\n",
    "        # SFS\n",
    "        while len(current_features) < self.n_features_to_select:\n",
    "            best_score = -np.inf  # 最良スコアの初期化（マイナス無限大）\n",
    "            best_feature = None\n",
    "\n",
    "            # 追加すべき特徴量を1つ決める\n",
    "            for feature in remaining_features:\n",
    "                temp_features = current_features + [\n",
    "                    feature\n",
    "                ]  # 現在の特徴量リストに新しい特徴量を加えた仮のリストを作成\n",
    "                score = self.evaluate_subset(\n",
    "                    X[:, temp_features], y\n",
    "                )  # 仮のリストに基づいて評価\n",
    "                if score > best_score:  # 評価スコアが最良スコアよりも大きいときは更新\n",
    "                    print(score)\n",
    "                    best_score = score\n",
    "                    best_feature = feature\n",
    "\n",
    "            # current_featuresとremaining_featuresの更新\n",
    "            if best_feature is not None:\n",
    "                current_features.append(best_feature)\n",
    "                remaining_features.remove(best_feature)\n",
    "                self.selected_features_ = current_features\n",
    "            else:\n",
    "                break\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        check_array(X)  # Xを検証\n",
    "        return X[:, self.selected_features_]  # 選択された特徴量だけを抽出して返す\n",
    "\n",
    "    def evaluate_subset(self, X_subset, y):  # EMクラスタリング\n",
    "        gmm = GaussianMixture(\n",
    "            n_components=self.n_clusters, random_state=self.random_state\n",
    "        )\n",
    "        gmm.fit(X_subset)\n",
    "\n",
    "        # GMMのパラメータ\n",
    "        means = gmm.means_  # 各クラスタの平均ベクトル\n",
    "        covariances = gmm.covariances_  # 各クラスタの共分散行列\n",
    "        weights = gmm.weights_  # 各クラスタの混合係数\n",
    "        overall_mean = np.sum(\n",
    "            [weights[k] * means[k] for k in range(self.n_clusters)], axis=0\n",
    "        )\n",
    "        # クラスタ内分離行列\n",
    "        S_W = np.sum(\n",
    "            [weights[k] * covariances[k] for k in range(self.n_clusters)], axis=0\n",
    "        )\n",
    "\n",
    "        # クラスタ間分離行列\n",
    "        S_B = np.sum(\n",
    "            [\n",
    "                weights[k] * np.outer(means[k] - overall_mean, means[k] - overall_mean)\n",
    "                for k in range(self.n_clusters)\n",
    "            ],\n",
    "            axis=0,\n",
    "        )\n",
    "\n",
    "        # 散乱分離性\n",
    "        scatter_discriminability = np.trace(np.linalg.inv(S_W).dot(S_B))\n",
    "        return scatter_discriminability\n",
    "\n",
    "    def get_feature_index_out(self):\n",
    "        # 選択された特徴量のインデックスを返す\n",
    "        return np.array(self.selected_features_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.utils import check_X_y, check_array\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class Wrapper(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, n_features_to_select, n_clusters, random_state=None):\n",
    "        self.n_features_to_select = n_features_to_select  # 選択する特徴量の数\n",
    "        self.n_clusters = n_clusters  # クラスタ数\n",
    "        self.random_state = random_state  # 乱数シード\n",
    "\n",
    "    def FSSEM(self, X, y):\n",
    "        X, y = check_X_y(X, y)  # データの整合性確認\n",
    "\n",
    "        self.n_features_ = X.shape[1]  # 特徴量の総数\n",
    "        self.selected_features_ = []  # 特徴量サブセット初期化\n",
    "\n",
    "        # 現在選択されている特徴量のインデックスを格納する用\n",
    "        current_features = []\n",
    "        # 選択されていない特徴量のインデックスを格納する用\n",
    "        remaining_features = list(range(X.shape[1]))\n",
    "\n",
    "        # SFS\n",
    "        while len(current_features) < self.n_features_to_select:\n",
    "            best_score = -np.inf  # 最良スコアの初期化（マイナス無限大）\n",
    "            best_feature = None\n",
    "\n",
    "            # 追加すべき特徴量を1つ決める\n",
    "            for feature in remaining_features:\n",
    "                temp_features = current_features + [\n",
    "                    feature\n",
    "                ]  # 現在の特徴量リストに新しい特徴量を加えた仮のリストを作成\n",
    "                score = self.evaluate_subset(\n",
    "                    X[:, temp_features], y\n",
    "                )  # 仮のリストに基づいて評価\n",
    "                if score > best_score:  # 評価スコアが最良スコアよりも大きいときは更新\n",
    "                    best_score = score\n",
    "                    best_feature = feature\n",
    "\n",
    "            # current_featuresとremaining_featuresの更新\n",
    "            if best_feature is not None:\n",
    "                current_features.append(best_feature)\n",
    "                remaining_features.remove(best_feature)\n",
    "                self.selected_features_ = current_features\n",
    "            else:\n",
    "                break\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        check_array(X)  # Xを検証\n",
    "        return X[:, self.selected_features_]  # 選択された特徴量だけを抽出して返す\n",
    "\n",
    "    def evaluate_subset(self, X_subset, y):  # EMクラスタリング\n",
    "        gmm = GaussianMixture(\n",
    "            n_components=self.n_clusters, random_state=self.random_state\n",
    "        )\n",
    "        gmm.fit(X_subset)\n",
    "\n",
    "        # GMMのパラメータ\n",
    "        means = gmm.means_  # 各クラスタの平均ベクトル\n",
    "        covariances = gmm.covariances_  # 各クラスタの共分散行列\n",
    "        weights = gmm.weights_  # 各クラスタの混合係数\n",
    "        overall_mean = np.sum(\n",
    "            [weights[k] * means[k] for k in range(self.n_clusters)], axis=0\n",
    "        )\n",
    "        # クラスタ内分離行列\n",
    "        S_W = np.sum(\n",
    "            [weights[k] * covariances[k] for k in range(self.n_clusters)], axis=0\n",
    "        )\n",
    "\n",
    "        # クラスタ間分離行列\n",
    "        S_B = np.sum(\n",
    "            [\n",
    "                weights[k] * np.outer(means[k] - overall_mean, means[k] - overall_mean)\n",
    "                for k in range(self.n_clusters)\n",
    "            ],\n",
    "            axis=0,\n",
    "        )\n",
    "\n",
    "        # 散乱分離性\n",
    "        scatter_discriminability = np.trace(np.linalg.inv(S_W).dot(S_B))\n",
    "        return scatter_discriminability\n",
    "\n",
    "    def get_feature_index_out(self):\n",
    "        # 選択された特徴量のインデックスを返す\n",
    "        return np.array(self.selected_features_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HaruMomozu\\Desktop\\momozu\\ABtesting\\.venv\\Lib\\site-packages\\sklearn\\base.py:1473: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (3). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features indices: [1 0 2]\n"
     ]
    }
   ],
   "source": [
    "# 特徴量選択のためのインスタンスを作成\n",
    "n_features_to_select = 3  # 選択したい特徴量の数\n",
    "fssem = Wrapper(\n",
    "    n_features_to_select=n_features_to_select, n_clusters=3, random_state=42\n",
    ")\n",
    "\n",
    "# FSSEM\n",
    "fssem.FSSEM(X_scaled, y)  # 選択された特徴量\n",
    "selected_features = fssem.get_feature_index_out()\n",
    "print(f\"Selected features indices: {selected_features}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

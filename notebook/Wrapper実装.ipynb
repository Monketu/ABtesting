{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils.validation import check_array, check_X_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      RIDAGEYR  RIAGENDR  PAQ605  BMXBMI  LBXGLU  DIQ010  LBXGLT  LBXIN\n",
      "0         61.0       2.0     2.0    35.7   110.0     2.0   150.0  14.91\n",
      "1         26.0       2.0     2.0    20.3    89.0     2.0    80.0   3.85\n",
      "2         16.0       1.0     2.0    23.2    89.0     2.0    68.0   6.14\n",
      "3         32.0       1.0     2.0    28.9   104.0     2.0    84.0  16.15\n",
      "4         38.0       2.0     1.0    35.9   103.0     2.0    81.0  10.92\n",
      "...        ...       ...     ...     ...     ...     ...     ...    ...\n",
      "2165      38.0       2.0     2.0    33.5   100.0     2.0    73.0   6.53\n",
      "2166      61.0       1.0     2.0    30.0    93.0     2.0   208.0  13.02\n",
      "2167      34.0       1.0     2.0    23.7   103.0     2.0   124.0  21.41\n",
      "2168      60.0       2.0     2.0    27.4    90.0     2.0   108.0   4.99\n",
      "2169      26.0       1.0     2.0    24.5   108.0     2.0   108.0   3.76\n",
      "\n",
      "[2170 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "df = pd.read_csv(\n",
    "    R\"C:\\Users\\HaruMomozu\\Documents\\オンラインデータ\\NHANES_age_prediction.csv\"\n",
    ")\n",
    "df = df.drop(columns=[\"SEQN\", \"age_group\"])\n",
    "\n",
    "obj = \"BMXBMI\"\n",
    "features_list = [\n",
    "    \"RIDAGEYR\",  # 年齢（連続変数）\n",
    "    \"RIAGENDR\",  # 性別（1:Male, 2:Female)\n",
    "    \"PAQ605\",  # 運動有無(1:日常的に運動する, 2:運動しない)\n",
    "    \"LBXGLU\",  # 断食後の血糖値（連続変数）\n",
    "    \"DIQ010\",  # 糖尿病の有無(0:なし、1:あり)\n",
    "    \"LBXGLT\",  # 口内の健康状態（連続変数）\n",
    "    \"LBXIN\",  # 血中インスリン濃度（連続変数）\n",
    "]\n",
    "\n",
    "\n",
    "# 外れ値の除去\n",
    "def remove_outliers_zscore(data, metric, threshold=2):\n",
    "    z_scores = np.abs(stats.zscore(data[metric]))\n",
    "    data = data[(z_scores < threshold)]\n",
    "    return data\n",
    "\n",
    "\n",
    "df = remove_outliers_zscore(df, obj)\n",
    "\n",
    "# process_features\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "X = df[features_list]\n",
    "# 数値列の標準化\n",
    "scaler = StandardScaler()\n",
    "scaled_features = scaler.fit_transform(X)\n",
    "\n",
    "X_scaled = pd.DataFrame(scaled_features, columns=features_list)\n",
    "y = df[obj]  # 目的変数\n",
    "\n",
    "# 行を詰める\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SFS(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, n_features_to_select):\n",
    "        self.n_features_to_select = n_features_to_select  # 選択する特徴量の数\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        X, y = check_X_y(X, y)  # データの整合性確認\n",
    "        self.n_features_ = X.shape[1]  # 特徴量の総数\n",
    "        self.selected_features_ = []  # 特徴量サブセット初期化\n",
    "\n",
    "        # Initialize the list of selected features\n",
    "        current_features = []  # 現在選択されている特徴量を格納する用（ここに良い特徴量を追加していく）\n",
    "        remaining_features = list(\n",
    "            range(X.shape[1])\n",
    "        )  # 選択されていない特徴量を格納する用（ここから良い特徴量を削除していく）\n",
    "\n",
    "        while len(current_features) < self.n_features_to_select:\n",
    "            best_score = -np.inf\n",
    "            best_feature = None\n",
    "\n",
    "            for feature in remaining_features:\n",
    "                temp_features = current_features + [feature]\n",
    "                score = self.evaluate_subset(X[:, temp_features], y)\n",
    "                if score > best_score:\n",
    "                    best_score = score\n",
    "                    best_feature = feature\n",
    "\n",
    "            if best_feature is not None:\n",
    "                current_features.append(best_feature)\n",
    "                remaining_features.remove(best_feature)\n",
    "                self.selected_features_ = current_features\n",
    "            else:\n",
    "                break\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        check_array(X)  # Xを検証\n",
    "        return X[:, self.selected_features_]  # 選択された特徴量だけを抽出して返す\n",
    "\n",
    "    def evaluate_subset(self, X_subset, y):\n",
    "        # EMクラスタリング\n",
    "        gmm = GaussianMixture(n_components=len(np.unique(y)), random_state=42)\n",
    "        gmm.fit(X_subset)\n",
    "        labels = gmm.predict(X_subset)\n",
    "\n",
    "        # クラスごとの平均を計算\n",
    "        class_means = np.array(\n",
    "            [X_subset[y == label].mean(axis=0) for label in np.unique(y)]\n",
    "        )\n",
    "        overall_mean = X_subset.mean(axis=0)\n",
    "\n",
    "        # クラス内散乱行列 (S_W)\n",
    "        S_W = np.sum(\n",
    "            [\n",
    "                np.cov(X_subset[y == label].T, bias=True) * (np.sum(y == label) - 1)\n",
    "                for label in np.unique(y)\n",
    "            ],\n",
    "            axis=0,\n",
    "        )\n",
    "\n",
    "        # クラス間散乱行列 (S_B)\n",
    "        S_B = np.sum(\n",
    "            [\n",
    "                (\n",
    "                    np.sum(y == label)\n",
    "                    * np.outer(mean - overall_mean, mean - overall_mean)\n",
    "                )\n",
    "                for label, mean in zip(np.unique(y), class_means)\n",
    "            ],\n",
    "            axis=0,\n",
    "        )\n",
    "\n",
    "        # Debugging: Print shapes\n",
    "        print(f\"Shape of S_W: {S_W.shape}\")\n",
    "        print(f\"Shape of S_B: {S_B.shape}\")\n",
    "\n",
    "        # Scatter Discriminability\n",
    "        scatter_discriminability = np.trace(np.linalg.inv(S_W).dot(S_B))\n",
    "        print(f\"Shape of tr: {scatter_discriminability.shape}\")\n",
    "        return scatter_discriminability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of S_W: ()\n",
      "Shape of S_B: (1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HaruMomozu\\Desktop\\momozu\\ABtesting\\.venv\\Lib\\site-packages\\sklearn\\base.py:1473: ConvergenceWarning: Number of distinct clusters (69) found smaller than n_clusters (251). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "ename": "LinAlgError",
     "evalue": "0-dimensional array given. Array must be at least two-dimensional",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLinAlgError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# SFSで特徴量選択\u001b[39;00m\n\u001b[0;32m      7\u001b[0m sfs \u001b[38;5;241m=\u001b[39m SFS(n_features_to_select\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m----> 8\u001b[0m \u001b[43msfs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# 訓練データとテストデータを選択した特徴だけで変換\u001b[39;00m\n\u001b[0;32m     11\u001b[0m X_train_selected \u001b[38;5;241m=\u001b[39m sfs\u001b[38;5;241m.\u001b[39mtransform(X_train)\n",
      "Cell \u001b[1;32mIn[16], line 22\u001b[0m, in \u001b[0;36mSFS.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m feature \u001b[38;5;129;01min\u001b[39;00m remaining_features:\n\u001b[0;32m     21\u001b[0m     temp_features \u001b[38;5;241m=\u001b[39m current_features \u001b[38;5;241m+\u001b[39m [feature]\n\u001b[1;32m---> 22\u001b[0m     score \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate_subset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemp_features\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m score \u001b[38;5;241m>\u001b[39m best_score:\n\u001b[0;32m     24\u001b[0m         best_score \u001b[38;5;241m=\u001b[39m score\n",
      "Cell \u001b[1;32mIn[16], line 78\u001b[0m, in \u001b[0;36mSFS.evaluate_subset\u001b[1;34m(self, X_subset, y)\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShape of S_B: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mS_B\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     77\u001b[0m \u001b[38;5;66;03m# Scatter Discriminability\u001b[39;00m\n\u001b[1;32m---> 78\u001b[0m scatter_discriminability \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mtrace(\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinalg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mS_W\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mdot(S_B))\n\u001b[0;32m     79\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShape of tr: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mscatter_discriminability\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     80\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m scatter_discriminability\n",
      "File \u001b[1;32mc:\\Users\\HaruMomozu\\Desktop\\momozu\\ABtesting\\.venv\\Lib\\site-packages\\numpy\\linalg\\_linalg.py:601\u001b[0m, in \u001b[0;36minv\u001b[1;34m(a)\u001b[0m\n\u001b[0;32m    495\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    496\u001b[0m \u001b[38;5;124;03mCompute the inverse of a matrix.\u001b[39;00m\n\u001b[0;32m    497\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    598\u001b[0m \n\u001b[0;32m    599\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    600\u001b[0m a, wrap \u001b[38;5;241m=\u001b[39m _makearray(a)\n\u001b[1;32m--> 601\u001b[0m \u001b[43m_assert_stacked_2d\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    602\u001b[0m _assert_stacked_square(a)\n\u001b[0;32m    603\u001b[0m t, result_t \u001b[38;5;241m=\u001b[39m _commonType(a)\n",
      "File \u001b[1;32mc:\\Users\\HaruMomozu\\Desktop\\momozu\\ABtesting\\.venv\\Lib\\site-packages\\numpy\\linalg\\_linalg.py:195\u001b[0m, in \u001b[0;36m_assert_stacked_2d\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    193\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m arrays:\n\u001b[0;32m    194\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m a\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m--> 195\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LinAlgError(\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m-dimensional array given. Array must be \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    196\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mat least two-dimensional\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m a\u001b[38;5;241m.\u001b[39mndim)\n",
      "\u001b[1;31mLinAlgError\u001b[0m: 0-dimensional array given. Array must be at least two-dimensional"
     ]
    }
   ],
   "source": [
    "# データの分割\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "# SFSで特徴量選択\n",
    "sfs = SFS(n_features_to_select=2)\n",
    "sfs.fit(X_train, y_train)\n",
    "\n",
    "# 訓練データとテストデータを選択した特徴だけで変換\n",
    "X_train_selected = sfs.transform(X_train)\n",
    "X_test_selected = sfs.transform(X_test)\n",
    "\n",
    "# 選択した特徴量を用いてSVMモデルを訓練\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "classifier = SVC()\n",
    "classifier.fit(X_train_selected, y_train)\n",
    "\n",
    "# 予測と評価\n",
    "y_pred = classifier.predict(X_test_selected)\n",
    "score = f1_score(y_test, y_pred, average=\"weighted\")\n",
    "\n",
    "print(f\"Selected Features: {sfs.selected_features_}\")\n",
    "print(f\"F1 Score: {score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

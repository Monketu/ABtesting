{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.1 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"c:\\Users\\HaruMomozu\\Desktop\\momozu\\ABtesting\\.venv\\Lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"c:\\Users\\HaruMomozu\\Desktop\\momozu\\ABtesting\\.venv\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"c:\\Users\\HaruMomozu\\Desktop\\momozu\\ABtesting\\.venv\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"c:\\Users\\HaruMomozu\\Desktop\\momozu\\ABtesting\\.venv\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Users\\HaruMomozu\\.rye\\py\\cpython@3.12.4\\Lib\\asyncio\\base_events.py\", line 641, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Users\\HaruMomozu\\.rye\\py\\cpython@3.12.4\\Lib\\asyncio\\base_events.py\", line 1987, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Users\\HaruMomozu\\.rye\\py\\cpython@3.12.4\\Lib\\asyncio\\events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"c:\\Users\\HaruMomozu\\Desktop\\momozu\\ABtesting\\.venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"c:\\Users\\HaruMomozu\\Desktop\\momozu\\ABtesting\\.venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"c:\\Users\\HaruMomozu\\Desktop\\momozu\\ABtesting\\.venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"c:\\Users\\HaruMomozu\\Desktop\\momozu\\ABtesting\\.venv\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"c:\\Users\\HaruMomozu\\Desktop\\momozu\\ABtesting\\.venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"c:\\Users\\HaruMomozu\\Desktop\\momozu\\ABtesting\\.venv\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"c:\\Users\\HaruMomozu\\Desktop\\momozu\\ABtesting\\.venv\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"c:\\Users\\HaruMomozu\\Desktop\\momozu\\ABtesting\\.venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"c:\\Users\\HaruMomozu\\Desktop\\momozu\\ABtesting\\.venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"c:\\Users\\HaruMomozu\\Desktop\\momozu\\ABtesting\\.venv\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"c:\\Users\\HaruMomozu\\Desktop\\momozu\\ABtesting\\.venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"c:\\Users\\HaruMomozu\\Desktop\\momozu\\ABtesting\\.venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"c:\\Users\\HaruMomozu\\Desktop\\momozu\\ABtesting\\.venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\HaruMomozu\\AppData\\Local\\Temp\\ipykernel_19812\\1091100056.py\", line 10, in <module>\n",
      "    from lightning.pytorch import seed_everything\n",
      "  File \"c:\\Users\\HaruMomozu\\Desktop\\momozu\\ABtesting\\.venv\\Lib\\site-packages\\lightning\\__init__.py\", line 18, in <module>\n",
      "    from lightning.fabric.fabric import Fabric  # noqa: E402\n",
      "  File \"c:\\Users\\HaruMomozu\\Desktop\\momozu\\ABtesting\\.venv\\Lib\\site-packages\\lightning\\fabric\\__init__.py\", line 30, in <module>\n",
      "    from lightning.fabric.fabric import Fabric  # noqa: E402\n",
      "  File \"c:\\Users\\HaruMomozu\\Desktop\\momozu\\ABtesting\\.venv\\Lib\\site-packages\\lightning\\fabric\\fabric.py\", line 35, in <module>\n",
      "    import torch\n",
      "  File \"c:\\Users\\HaruMomozu\\Desktop\\momozu\\ABtesting\\.venv\\Lib\\site-packages\\torch\\__init__.py\", line 2120, in <module>\n",
      "    from torch._higher_order_ops import cond\n",
      "  File \"c:\\Users\\HaruMomozu\\Desktop\\momozu\\ABtesting\\.venv\\Lib\\site-packages\\torch\\_higher_order_ops\\__init__.py\", line 1, in <module>\n",
      "    from .cond import cond\n",
      "  File \"c:\\Users\\HaruMomozu\\Desktop\\momozu\\ABtesting\\.venv\\Lib\\site-packages\\torch\\_higher_order_ops\\cond.py\", line 5, in <module>\n",
      "    import torch._subclasses.functional_tensor\n",
      "  File \"c:\\Users\\HaruMomozu\\Desktop\\momozu\\ABtesting\\.venv\\Lib\\site-packages\\torch\\_subclasses\\functional_tensor.py\", line 42, in <module>\n",
      "    class FunctionalTensor(torch.Tensor):\n",
      "  File \"c:\\Users\\HaruMomozu\\Desktop\\momozu\\ABtesting\\.venv\\Lib\\site-packages\\torch\\_subclasses\\functional_tensor.py\", line 258, in FunctionalTensor\n",
      "    cpu = _conversion_method_template(device=torch.device(\"cpu\"))\n",
      "c:\\Users\\HaruMomozu\\Desktop\\momozu\\ABtesting\\.venv\\Lib\\site-packages\\torch\\_subclasses\\functional_tensor.py:258: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\utils\\tensor_numpy.cpp:84.)\n",
      "  cpu = _conversion_method_template(device=torch.device(\"cpu\"))\n",
      "Seed set to 8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils.validation import check_array, check_X_y\n",
    "\n",
    "import japanize_matplotlib  # noqa\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns  # データ可視化ライブラリ\n",
    "from lightning.pytorch import seed_everything\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy import stats\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "from abc import ABCMeta, abstractmethod\n",
    "\n",
    "from numpy.typing import NDArray\n",
    "\n",
    "from typing import Optional\n",
    "\n",
    "plt.style.use(\"ggplot\")\n",
    "seed_everything(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# データの前処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 外れ値の除去\n",
    "def remove_outliers_zscore(data, metric, threshold=2):\n",
    "    z_scores = np.abs(stats.zscore(data[metric]))\n",
    "    data = data[(z_scores < threshold)]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\n",
    "    R\"C:\\Users\\HaruMomozu\\Documents\\オンラインデータ\\NHANES_age_prediction.csv\"\n",
    ")\n",
    "df1 = df1.drop(columns=[\"SEQN\", \"age_group\"])\n",
    "\n",
    "obj1 = \"BMXBMI\"\n",
    "features_list1 = [\n",
    "    \"RIDAGEYR\",  # 年齢（連続変数）\n",
    "    \"RIAGENDR\",  # 性別（1:Male, 2:Female)\n",
    "    \"PAQ605\",  # 運動有無(1:日常的に運動する, 2:運動しない)\n",
    "    \"LBXGLU\",  # 断食後の血糖値（連続変数）\n",
    "    \"DIQ010\",  # 糖尿病の有無(0:なし、1:あり)\n",
    "    \"LBXGLT\",  # 口内の健康状態（連続変数）\n",
    "    \"LBXIN\",  # 血中インスリン濃度（連続変数）\n",
    "]\n",
    "df1 = df1[df1[\"PAQ605\"] != 7.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv(\n",
    "    R\"C:\\Users\\HaruMomozu\\Documents\\オンラインデータ\\OnlineNewsPopularity\\OnlinenewsPopularity.csv\"\n",
    ")\n",
    "df2 = df2.drop(columns=[\"url\"])\n",
    "df2 = df2.drop(columns=[\" timedelta\"])\n",
    "\n",
    "obj2 = \" shares\"\n",
    "features_list2 = [col for col in list(df2.columns) if col != \" shares\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = pd.read_csv(\n",
    "    R\"C:\\Users\\HaruMomozu\\Documents\\オンラインデータ\\USCensus1990.data.txt\",\n",
    "    delimiter=\",\",\n",
    ")\n",
    "\n",
    "obj3 = \"iFertil\"\n",
    "features_list3 = [col for col in list(df3.columns) if col != obj3]\n",
    "features_list3_20 = features_list3[:20]\n",
    "print(features_list3_20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = pd.read_csv(\n",
    "    R\"C:\\Users\\HaruMomozu\\Documents\\aug_first_cpn_data_for_ab_test_sensibility_tsukuba.csv\"\n",
    ")\n",
    "\n",
    "obj4 = \"GMV\"\n",
    "features_list4 = [\n",
    "    \"hist_4_day_buy_num\",\n",
    "    \"hist_4_day_gmv\",\n",
    "    \"his_4_day_is_buy\",\n",
    "    \"hist_30_day_buy_days\",\n",
    "    \"hist_30_day_buy_num\",\n",
    "    \"hist_30_day_gmv\",\n",
    "    \"hist_30_day_buy_recency\",\n",
    "    \"hist_30_day_pay_days\",\n",
    "    \"hist_30_day_atpu\",\n",
    "    \"hist_30_day_gpv\",\n",
    "    \"hist_30_day_pay_recency\",\n",
    "    \"hist_30_day_list_days\",\n",
    "    \"hist_30_day_list_num\",\n",
    "    \"hist_30_day_list_recency\",\n",
    "    \"hist_30_day_like_count\",\n",
    "    \"hist_30_day_like_count_not_deleted\",\n",
    "    \"hist_30_day_like_recency\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df1  # 選ぶ\n",
    "obj = obj1  # 選ぶ\n",
    "features_list = features_list1  # 選ぶ\n",
    "\n",
    "df = remove_outliers_zscore(df, obj)\n",
    "\n",
    "X = df[features_list]\n",
    "# 数値列の標準化\n",
    "scaler = StandardScaler()\n",
    "scaled_features = scaler.fit_transform(X)\n",
    "X_scaled = pd.DataFrame(scaled_features, columns=features_list)\n",
    "\n",
    "y = df[obj]  # 目的変数\n",
    "\n",
    "# 行を詰める\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FSSEM でクラスタリング"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wrapperクラス"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Wrapper(BaseEstimator, TransformerMixin):\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_features_to_select,\n",
    "        n_clusters,\n",
    "        criterion=\"ml\",\n",
    "        clustering_method=\"gmm\",\n",
    "        random_state=None,\n",
    "    ):\n",
    "        self.n_features_to_select = n_features_to_select  # 特徴量数\n",
    "        self.n_clusters = n_clusters  # クラスタ数\n",
    "        self.criterion = criterion  # 特徴量選択基準\n",
    "        self.clustering_method = clustering_method  # クラスタリング手法\n",
    "        self.random_state = random_state\n",
    "\n",
    "    def FSS(self, X, y):\n",
    "        X, y = check_X_y(X, y)\n",
    "\n",
    "        n_features = X.shape[1]  # 総特徴量数\n",
    "        self.selected_features_ = []  # ここに選択した特徴量を入れる\n",
    "\n",
    "        # 選ばれた特徴量と残っている特徴量の初期化\n",
    "        current_features = []\n",
    "        remaining_features = list(range(n_features))\n",
    "\n",
    "        # 特徴量サブセットのスコアを格納するための辞書（余計な計算を避けるため）\n",
    "        cluster_cache = {}\n",
    "\n",
    "        while len(current_features) < self.n_features_to_select:\n",
    "            # print(current_features)\n",
    "            best_score = -np.inf  # best score初期化（-∞）\n",
    "            best_feature = None  # 選ぶ特徴量の初期化\n",
    "\n",
    "            for feature in remaining_features:\n",
    "                temp_features = tuple(\n",
    "                    current_features + [feature]\n",
    "                )  # 特徴量をひとつ加え、score計算\n",
    "\n",
    "                if temp_features in cluster_cache:\n",
    "                    score = cluster_cache[temp_features]\n",
    "                else:\n",
    "                    score = self.evaluate_subset(X[:, temp_features], y)\n",
    "                    cluster_cache[temp_features] = score\n",
    "\n",
    "                if score > best_score:\n",
    "                    best_score = score\n",
    "                    best_feature = feature\n",
    "\n",
    "            if best_feature is not None:\n",
    "                current_features.append(\n",
    "                    best_feature\n",
    "                )  # best feature をcurrent features に追加\n",
    "                remaining_features.remove(\n",
    "                    best_feature\n",
    "                )  # best feature をremaining features から取り除く\n",
    "                self.selected_features_ = current_features\n",
    "            else:\n",
    "                break\n",
    "\n",
    "        # 選ばれた特徴量サブセットでクラスタリング\n",
    "        final_features = X[:, self.selected_features_]\n",
    "        if self.clustering_method == \"gmm\":\n",
    "            self.final_model_ = GaussianMixture(\n",
    "                n_components=self.n_clusters, random_state=self.random_state\n",
    "            )\n",
    "        elif self.clustering_method == \"kmeans\":\n",
    "            self.final_model_ = KMeans(\n",
    "                n_clusters=self.n_clusters, random_state=self.random_state\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown clustering method: {self.clustering_method}\")\n",
    "\n",
    "        self.final_model_.fit(final_features)\n",
    "        self.final_cluster_assignments_ = self.final_model_.predict(final_features)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def evaluate_subset(self, X_subset, y):  # 特徴量サブセットの評価\n",
    "        if self.clustering_method == \"gmm\":\n",
    "            return self.evaluate_gmm(X_subset, y)\n",
    "        elif self.clustering_method == \"kmeans\":\n",
    "            return self.evaluate_kmeans(X_subset, y)\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown clustering method: {self.clustering_method}\")\n",
    "\n",
    "    def evaluate_gmm(self, X_subset, y):  # EMクラスタリングのときの評価基準\n",
    "        gmm = GaussianMixture(\n",
    "            n_components=self.n_clusters, random_state=self.random_state\n",
    "        )\n",
    "        gmm.fit(X_subset)\n",
    "\n",
    "        if self.criterion == \"scatter\":\n",
    "            return self.scatter_discriminability_gmm(gmm, X_subset)\n",
    "        elif self.criterion == \"ml\":\n",
    "            return gmm.score(X_subset)\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown criterion: {self.criterion}\")\n",
    "\n",
    "    def evaluate_kmeans(self, X_subset, y):  # kmeansのときの評価基準\n",
    "        kmeans = KMeans(n_clusters=self.n_clusters, random_state=self.random_state)\n",
    "        kmeans.fit(X_subset)\n",
    "\n",
    "        if self.criterion == \"scatter\":\n",
    "            return self.scatter_discriminability_kmeans(kmeans, X_subset)\n",
    "        elif self.criterion == \"ml\":\n",
    "            return -kmeans.score(X_subset)\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown criterion: {self.criterion}\")\n",
    "\n",
    "    def scatter_discriminability_gmm(self, gmm, X_subset):  # EMのときの散乱分離性\n",
    "        means = gmm.means_  # 平均ベクトル\n",
    "        covariances = gmm.covariances_  # 共分散行列\n",
    "        weights = gmm.weights_  # 混合比率\n",
    "        overall_mean = np.sum(\n",
    "            weights[:, np.newaxis] * means, axis=0\n",
    "        )  # 標本平均 #np.newaxisを使って1次元配列から2次元配列にする\n",
    "\n",
    "        S_W = np.sum(weights[:, np.newaxis, np.newaxis] * covariances, axis=0)\n",
    "        S_B = np.sum(\n",
    "            weights[:, np.newaxis, np.newaxis]\n",
    "            * np.einsum(\"...i,...j->...ij\", means - overall_mean, means - overall_mean),\n",
    "            axis=0,\n",
    "        )\n",
    "        scatter_discriminability = np.trace(np.linalg.solve(S_W, S_B))\n",
    "        return scatter_discriminability\n",
    "\n",
    "    def scatter_discriminability_kmeans(\n",
    "        self, kmeans, X_subset\n",
    "    ):  # kmeansのときの散乱分離性\n",
    "        labels = kmeans.labels_\n",
    "        cluster_centers = kmeans.cluster_centers_\n",
    "\n",
    "        sw_i_list = []\n",
    "        for i in range(self.n_clusters):\n",
    "            cluster_points = X_subset[labels == i]\n",
    "\n",
    "            if cluster_points.shape[0] == 1:\n",
    "                # データポイントが1つの場合はゼロ行列を使用\n",
    "                sw_i = np.zeros((X_subset.shape[1], X_subset.shape[1]))\n",
    "            else:\n",
    "                # 共分散行列を計算し、スカラー値ではなく2次元行列になることを保証\n",
    "                sw_i = np.cov(cluster_points, rowvar=False) * np.sum(labels == i)\n",
    "                if np.isscalar(sw_i):  # スカラー値のとき\n",
    "                    sw_i = np.array([[sw_i]])\n",
    "            sw_i_list.append(sw_i)\n",
    "\n",
    "        # 全クラスターの S_W を合計\n",
    "        S_W = np.sum(sw_i_list, axis=0)\n",
    "\n",
    "        # クラスター間散布行列 S_B を計算\n",
    "        overall_mean = np.mean(X_subset, axis=0)\n",
    "        S_B = sum(\n",
    "            np.sum(labels == i)\n",
    "            * np.outer(\n",
    "                cluster_centers[i] - overall_mean, cluster_centers[i] - overall_mean\n",
    "            )\n",
    "            for i in range(self.n_clusters)\n",
    "        )\n",
    "\n",
    "        # 散乱分離性を計算\n",
    "        scatter_discriminability = np.trace(np.linalg.solve(S_W, S_B))\n",
    "        return scatter_discriminability\n",
    "\n",
    "    def transform(self, X):\n",
    "        check_array(X)\n",
    "        return X[:, self.selected_features_]  # 選択された特徴量のデータをかえす\n",
    "\n",
    "    def get_feature_index_out(self):\n",
    "        return np.array(self.selected_features_)  # 選択された特徴量のインデックス\n",
    "\n",
    "    def get_final_cluster_assignments(self):\n",
    "        return self.final_cluster_assignments_  # 最終的なクラスタリング結果\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wrapperクラス確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import warnings\n",
    "# from sklearn.exceptions import ConvergenceWarning\n",
    "\n",
    "# warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "\n",
    "clusters = 5\n",
    "n_features_to_select = 5  # 選択したい特徴量の数\n",
    "\n",
    "fssem_tr = Wrapper(\n",
    "    n_features_to_select=n_features_to_select,\n",
    "    n_clusters=clusters,\n",
    "    criterion=\"scatter\",\n",
    "    clustering_method=\"gmm\",\n",
    "    random_state=0,\n",
    ")\n",
    "fssem_ml = Wrapper(\n",
    "    n_features_to_select=n_features_to_select,\n",
    "    n_clusters=clusters,\n",
    "    criterion=\"ml\",\n",
    "    clustering_method=\"gmm\",\n",
    "    random_state=0,\n",
    ")\n",
    "fsskmeans_tr = Wrapper(\n",
    "    n_features_to_select=n_features_to_select,\n",
    "    n_clusters=clusters,\n",
    "    criterion=\"scatter\",\n",
    "    clustering_method=\"kmeans\",\n",
    "    random_state=0,\n",
    ")\n",
    "fsskmeans_ml = Wrapper(\n",
    "    n_features_to_select=n_features_to_select,\n",
    "    n_clusters=clusters,\n",
    "    criterion=\"ml\",\n",
    "    clustering_method=\"kmeans\",\n",
    "    random_state=0,\n",
    ")\n",
    "instance_list = [fssem_tr, fssem_ml, fsskmeans_tr, fsskmeans_ml]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[84.20047893]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[278.88507961]]\n",
      "[[nan]]\n",
      "[[238.39349393]]\n",
      "[[179.88513473]]\n",
      "[[4.09910731e+02 8.60299566e-27]\n",
      " [8.60299566e-27 1.51269876e-25]]\n",
      "[[2.76837345e+02 5.11708874e-28]\n",
      " [5.11708874e-28 4.81245081e-26]]\n",
      "[[300.53759787 -19.63865038]\n",
      " [-19.63865038 605.02361222]]\n",
      "[[ 2.76762900e+02 -4.38810170e-28]\n",
      " [-4.38810170e-28  1.62208178e-27]]\n",
      "[[426.92618694 -77.89130051]\n",
      " [-77.89130051 634.62192432]]\n",
      "[[417.10988249 -77.01605036]\n",
      " [-77.01605036 610.48616593]]\n",
      "[[ 5.88679877e+02 -7.88565835e+00 -7.16665205e+00]\n",
      " [-7.88565835e+00  5.94985871e+02  2.81420666e-28]\n",
      " [-7.16665205e+00  2.81420666e-28  5.17648049e+01]]\n",
      "[[ 7.52462796e+02 -2.97362384e-28  1.91065355e+00]\n",
      " [-2.97362384e-28  1.67427705e-27 -2.18473301e-27]\n",
      " [ 1.91065355e+00 -2.18473301e-27  8.27735754e+01]]\n",
      "[[ 3.20927745e+02 -3.69059418e-01 -7.29271624e+01]\n",
      " [-3.69059418e-01  6.11849384e+02 -1.78513370e+01]\n",
      " [-7.29271624e+01 -1.78513370e+01  8.85013322e+02]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HaruMomozu\\Desktop\\momozu\\ABtesting\\.venv\\Lib\\site-packages\\sklearn\\base.py:1473: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\HaruMomozu\\Desktop\\momozu\\ABtesting\\.venv\\Lib\\site-packages\\numpy\\lib\\_function_base_impl.py:557: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis, **keepdims_kw)\n",
      "c:\\Users\\HaruMomozu\\Desktop\\momozu\\ABtesting\\.venv\\Lib\\site-packages\\numpy\\_core\\_methods.py:130: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = um.true_divide(\n",
      "C:\\Users\\HaruMomozu\\AppData\\Local\\Temp\\ipykernel_19812\\2283265616.py:142: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  sw_i = np.cov(cluster_points, rowvar=False) * np.sum(labels == i)\n",
      "c:\\Users\\HaruMomozu\\Desktop\\momozu\\ABtesting\\.venv\\Lib\\site-packages\\numpy\\lib\\_function_base_impl.py:2773: RuntimeWarning: divide by zero encountered in divide\n",
      "  c *= np.true_divide(1, fact)\n",
      "c:\\Users\\HaruMomozu\\Desktop\\momozu\\ABtesting\\.venv\\Lib\\site-packages\\numpy\\lib\\_function_base_impl.py:2773: RuntimeWarning: invalid value encountered in multiply\n",
      "  c *= np.true_divide(1, fact)\n",
      "c:\\Users\\HaruMomozu\\Desktop\\momozu\\ABtesting\\.venv\\Lib\\site-packages\\sklearn\\base.py:1473: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\HaruMomozu\\Desktop\\momozu\\ABtesting\\.venv\\Lib\\site-packages\\numpy\\lib\\_function_base_impl.py:557: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis, **keepdims_kw)\n",
      "c:\\Users\\HaruMomozu\\Desktop\\momozu\\ABtesting\\.venv\\Lib\\site-packages\\numpy\\_core\\_methods.py:130: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = um.true_divide(\n",
      "C:\\Users\\HaruMomozu\\AppData\\Local\\Temp\\ipykernel_19812\\2283265616.py:142: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  sw_i = np.cov(cluster_points, rowvar=False) * np.sum(labels == i)\n",
      "c:\\Users\\HaruMomozu\\Desktop\\momozu\\ABtesting\\.venv\\Lib\\site-packages\\numpy\\lib\\_function_base_impl.py:2773: RuntimeWarning: divide by zero encountered in divide\n",
      "  c *= np.true_divide(1, fact)\n",
      "c:\\Users\\HaruMomozu\\Desktop\\momozu\\ABtesting\\.venv\\Lib\\site-packages\\numpy\\lib\\_function_base_impl.py:2773: RuntimeWarning: invalid value encountered in multiply\n",
      "  c *= np.true_divide(1, fact)\n",
      "c:\\Users\\HaruMomozu\\Desktop\\momozu\\ABtesting\\.venv\\Lib\\site-packages\\sklearn\\base.py:1473: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\HaruMomozu\\Desktop\\momozu\\ABtesting\\.venv\\Lib\\site-packages\\numpy\\lib\\_function_base_impl.py:557: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis, **keepdims_kw)\n",
      "c:\\Users\\HaruMomozu\\Desktop\\momozu\\ABtesting\\.venv\\Lib\\site-packages\\numpy\\_core\\_methods.py:130: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = um.true_divide(\n",
      "C:\\Users\\HaruMomozu\\AppData\\Local\\Temp\\ipykernel_19812\\2283265616.py:142: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  sw_i = np.cov(cluster_points, rowvar=False) * np.sum(labels == i)\n",
      "c:\\Users\\HaruMomozu\\Desktop\\momozu\\ABtesting\\.venv\\Lib\\site-packages\\numpy\\lib\\_function_base_impl.py:2773: RuntimeWarning: divide by zero encountered in divide\n",
      "  c *= np.true_divide(1, fact)\n",
      "c:\\Users\\HaruMomozu\\Desktop\\momozu\\ABtesting\\.venv\\Lib\\site-packages\\numpy\\lib\\_function_base_impl.py:2773: RuntimeWarning: invalid value encountered in multiply\n",
      "  c *= np.true_divide(1, fact)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 6.34924784e+02  1.19303716e-27 -4.42777687e+00]\n",
      " [ 1.19303716e-27  1.78878283e-27 -5.67384244e-30]\n",
      " [-4.42777687e+00 -5.67384244e-30  1.08508409e+03]]\n",
      "[[393.71492531  26.02393158 -48.66057993]\n",
      " [ 26.02393158 587.82426197 -14.15174778]\n",
      " [-48.66057993 -14.15174778 974.97434933]]\n",
      "[[ 1.42108063e+03 -6.36553262e+01  3.29450412e+00 -1.52199698e+01]\n",
      " [-6.36553262e+01  5.98866779e+02 -6.91674624e-28 -1.52090180e+01]\n",
      " [ 3.29450412e+00 -6.91674624e-28  5.59536748e+01  6.54206657e+00]\n",
      " [-1.52199698e+01 -1.52090180e+01  6.54206657e+00  3.84971792e+02]]\n",
      "[[ 7.69922565e+02 -5.83475261e+01  3.74517216e+00  7.88555533e+01]\n",
      " [-5.83475261e+01  6.18146652e+02 -1.27505769e-27 -3.91533714e+01]\n",
      " [ 3.74517216e+00 -1.27505769e-27  5.57138734e+01  1.47856406e+00]\n",
      " [ 7.88555533e+01 -3.91533714e+01  1.47856406e+00  9.42316540e+02]]\n",
      "[[ 783.16853399   -4.96776461    2.26324736    6.98846373]\n",
      " [  -4.96776461  523.07872318   38.27679289   -4.50107583]\n",
      " [   2.26324736   38.27679289  106.46539053   13.06995926]\n",
      " [   6.98846373   -4.50107583   13.06995926 1118.79526973]]\n",
      "[[ 837.62075472   84.46727564   -7.96114885  -58.26555155]\n",
      " [  84.46727564 1511.31764916  -10.58592553   19.2427685 ]\n",
      " [  -7.96114885  -10.58592553  130.77383499  -47.13164488]\n",
      " [ -58.26555155   19.2427685   -47.13164488  961.5278256 ]]\n",
      "[[ 9.06873076e+02 -1.69124518e+01  3.29450412e+00 -3.90301259e+01\n",
      "  -2.34853126e+01]\n",
      " [-1.69124518e+01  5.94856036e+02 -4.11362281e-28 -1.72877773e+01\n",
      "  -2.74887350e+02]\n",
      " [ 3.29450412e+00 -4.11362281e-28  5.59536748e+01  6.54206657e+00\n",
      "   8.94145186e+00]\n",
      " [-3.90301259e+01 -1.72877773e+01  6.54206657e+00  9.30540893e+02\n",
      "  -1.56666962e+02]\n",
      " [-2.34853126e+01 -2.74887350e+02  8.94145186e+00 -1.56666962e+02\n",
      "   1.92286261e+03]]\n",
      "[[1182.12551341    9.17821247    4.6330858   -35.99895524  -79.43438517]\n",
      " [   9.17821247  587.61770315   25.51075784  -16.39795786 -188.59777579]\n",
      " [   4.6330858    25.51075784   96.26595651    3.26784603  -23.42351928]\n",
      " [ -35.99895524  -16.39795786    3.26784603  820.79484615  -33.25331082]\n",
      " [ -79.43438517 -188.59777579  -23.42351928  -33.25331082 1533.57641117]]\n",
      "[[ 9.30973987e+02 -4.43201623e+01  3.29450412e+00 -8.07279694e+01\n",
      "  -4.16192147e+01]\n",
      " [-4.43201623e+01  5.98294229e+02 -7.08555650e-28 -1.60092287e+01\n",
      "  -2.10233200e+01]\n",
      " [ 3.29450412e+00 -7.08555650e-28  5.59536748e+01  6.54206657e+00\n",
      "   2.31753296e+00]\n",
      " [-8.07279694e+01 -1.60092287e+01  6.54206657e+00  8.74609440e+02\n",
      "  -2.13450216e+01]\n",
      " [-4.16192147e+01 -2.10233200e+01  2.31753296e+00 -2.13450216e+01\n",
      "   2.12645617e+03]]\n",
      "Selected features indices: [0 4 2 1 3]\n",
      "選択された特徴量\n",
      "RIDAGEYR\n",
      "DIQ010\n",
      "PAQ605\n",
      "RIAGENDR\n",
      "LBXGLU\n",
      "[1 3 2 ... 2 1 2]\n",
      "(array([0, 1, 2, 3, 4], dtype=int32), array([379, 552, 553, 633,  52]))\n"
     ]
    }
   ],
   "source": [
    "fsskmeans_tr.FSS(X_scaled, y)  # 選択された特徴量\n",
    "selected_features = fsskmeans_tr.get_feature_index_out()\n",
    "print(f\"Selected features indices: {selected_features}\")\n",
    "\n",
    "print(\"選択された特徴量\")\n",
    "for n in selected_features:\n",
    "    print(X_scaled.columns[n])\n",
    "\n",
    "FSSEM_cluster = fsskmeans_tr.get_final_cluster_assignments()\n",
    "cluster_size = np.unique(FSSEM_cluster, return_counts=True)\n",
    "\n",
    "print(FSSEM_cluster)\n",
    "print(cluster_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FSSEM のクラスタリング結果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_with_clusterlabelrow = X_scaled.copy()\n",
    "X_with_clusterlabelrow[\"FSSEM_cluster\"] = FSSEM_cluster\n",
    "\n",
    "\n",
    "# 目的変数の分布\n",
    "sns.boxplot(  # 箱ひげ図\n",
    "    x=X_with_clusterlabelrow[\"FSSEM_cluster\"].astype(\n",
    "        str\n",
    "    ),  # x軸、as.type(str)で文字列に変換\n",
    "    y=y,  # y軸\n",
    "    hue=X_with_clusterlabelrow[\"FSSEM_cluster\"].astype(\n",
    "        str\n",
    "    ),  # クラスタラベルに基づいて色を付ける\n",
    "    palette=\"tab10\",  # カラーパレット指定\n",
    "    legend=False,\n",
    ")\n",
    "plt.title(\"クラスタリング結果（FSSEM）\", fontdict={\"fontsize\": \"large\"})\n",
    "plt.xlabel(\"クラスタラベル\")\n",
    "plt.ylabel(\"y\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

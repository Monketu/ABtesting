{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.1 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"c:\\Users\\HaruMomozu\\Desktop\\momozu\\ABtesting\\.venv\\Lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"c:\\Users\\HaruMomozu\\Desktop\\momozu\\ABtesting\\.venv\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"c:\\Users\\HaruMomozu\\Desktop\\momozu\\ABtesting\\.venv\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"c:\\Users\\HaruMomozu\\Desktop\\momozu\\ABtesting\\.venv\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Users\\HaruMomozu\\.rye\\py\\cpython@3.12.4\\Lib\\asyncio\\base_events.py\", line 641, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Users\\HaruMomozu\\.rye\\py\\cpython@3.12.4\\Lib\\asyncio\\base_events.py\", line 1987, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Users\\HaruMomozu\\.rye\\py\\cpython@3.12.4\\Lib\\asyncio\\events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"c:\\Users\\HaruMomozu\\Desktop\\momozu\\ABtesting\\.venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"c:\\Users\\HaruMomozu\\Desktop\\momozu\\ABtesting\\.venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"c:\\Users\\HaruMomozu\\Desktop\\momozu\\ABtesting\\.venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"c:\\Users\\HaruMomozu\\Desktop\\momozu\\ABtesting\\.venv\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"c:\\Users\\HaruMomozu\\Desktop\\momozu\\ABtesting\\.venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"c:\\Users\\HaruMomozu\\Desktop\\momozu\\ABtesting\\.venv\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"c:\\Users\\HaruMomozu\\Desktop\\momozu\\ABtesting\\.venv\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"c:\\Users\\HaruMomozu\\Desktop\\momozu\\ABtesting\\.venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"c:\\Users\\HaruMomozu\\Desktop\\momozu\\ABtesting\\.venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"c:\\Users\\HaruMomozu\\Desktop\\momozu\\ABtesting\\.venv\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"c:\\Users\\HaruMomozu\\Desktop\\momozu\\ABtesting\\.venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"c:\\Users\\HaruMomozu\\Desktop\\momozu\\ABtesting\\.venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"c:\\Users\\HaruMomozu\\Desktop\\momozu\\ABtesting\\.venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\HaruMomozu\\AppData\\Local\\Temp\\ipykernel_22464\\3493216968.py\", line 5, in <module>\n",
      "    from lightning.pytorch import seed_everything\n",
      "  File \"c:\\Users\\HaruMomozu\\Desktop\\momozu\\ABtesting\\.venv\\Lib\\site-packages\\lightning\\__init__.py\", line 18, in <module>\n",
      "    from lightning.fabric.fabric import Fabric  # noqa: E402\n",
      "  File \"c:\\Users\\HaruMomozu\\Desktop\\momozu\\ABtesting\\.venv\\Lib\\site-packages\\lightning\\fabric\\__init__.py\", line 30, in <module>\n",
      "    from lightning.fabric.fabric import Fabric  # noqa: E402\n",
      "  File \"c:\\Users\\HaruMomozu\\Desktop\\momozu\\ABtesting\\.venv\\Lib\\site-packages\\lightning\\fabric\\fabric.py\", line 35, in <module>\n",
      "    import torch\n",
      "  File \"c:\\Users\\HaruMomozu\\Desktop\\momozu\\ABtesting\\.venv\\Lib\\site-packages\\torch\\__init__.py\", line 2120, in <module>\n",
      "    from torch._higher_order_ops import cond\n",
      "  File \"c:\\Users\\HaruMomozu\\Desktop\\momozu\\ABtesting\\.venv\\Lib\\site-packages\\torch\\_higher_order_ops\\__init__.py\", line 1, in <module>\n",
      "    from .cond import cond\n",
      "  File \"c:\\Users\\HaruMomozu\\Desktop\\momozu\\ABtesting\\.venv\\Lib\\site-packages\\torch\\_higher_order_ops\\cond.py\", line 5, in <module>\n",
      "    import torch._subclasses.functional_tensor\n",
      "  File \"c:\\Users\\HaruMomozu\\Desktop\\momozu\\ABtesting\\.venv\\Lib\\site-packages\\torch\\_subclasses\\functional_tensor.py\", line 42, in <module>\n",
      "    class FunctionalTensor(torch.Tensor):\n",
      "  File \"c:\\Users\\HaruMomozu\\Desktop\\momozu\\ABtesting\\.venv\\Lib\\site-packages\\torch\\_subclasses\\functional_tensor.py\", line 258, in FunctionalTensor\n",
      "    cpu = _conversion_method_template(device=torch.device(\"cpu\"))\n",
      "c:\\Users\\HaruMomozu\\Desktop\\momozu\\ABtesting\\.venv\\Lib\\site-packages\\torch\\_subclasses\\functional_tensor.py:258: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\utils\\tensor_numpy.cpp:84.)\n",
      "  cpu = _conversion_method_template(device=torch.device(\"cpu\"))\n",
      "Seed set to 8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import japanize_matplotlib  # noqa\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from lightning.pytorch import seed_everything\n",
    "from scipy import stats\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils.validation import check_array, check_X_y\n",
    "\n",
    "plt.style.use(\"ggplot\")\n",
    "seed_everything(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris, load_wine\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.stats import mode\n",
    "\n",
    "# Irisデータセットの読み込み\n",
    "iris = load_iris()\n",
    "wine = load_wine()\n",
    "X = iris.data  ####選択\n",
    "y = iris.target  ###選択\n",
    "\n",
    "# 特徴量の標準化\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "print(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_gmm_with_kmeans(X, n_clusters=3, n_init=10, random_state=None):\n",
    "    best_gmm = None\n",
    "    best_log_likelihood = -np.inf\n",
    "    for j in range(n_init):\n",
    "        kmeans = KMeans(n_clusters=n_clusters, n_init=1, random_state=j).fit(X)\n",
    "        # centers_mean = np.mean(kmeans.cluster_centers_, axis=1).reshape(-1, 1)\n",
    "        gmm = GaussianMixture(\n",
    "            n_components=n_clusters,\n",
    "            covariance_type=\"full\",\n",
    "            means_init=kmeans.cluster_centers_,\n",
    "            random_state=random_state,\n",
    "        )\n",
    "        gmm.fit(X)\n",
    "        log_likelihood = gmm.score(X)\n",
    "        if log_likelihood > best_log_likelihood:\n",
    "            best_log_likelihood = log_likelihood\n",
    "            best_gmm = gmm\n",
    "    return best_gmm\n",
    "\n",
    "\n",
    "def kmeans_with_restarts(X, n_clusters=3, n_init=10, random_state=None):\n",
    "    best_kmeans = None\n",
    "    best_score = -np.inf\n",
    "    for j in range(n_init):\n",
    "        kmeans = KMeans(n_clusters=n_clusters, n_init=1, random_state=j)\n",
    "        kmeans.fit(X)\n",
    "        score = kmeans.score(X)  # 各モデルのスコア（対数尤度）\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_kmeans = kmeans\n",
    "    return best_kmeans\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import multivariate_normal\n",
    "\n",
    "\n",
    "class Wrapper(BaseEstimator, TransformerMixin):\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_features_to_select,\n",
    "        n_clusters,\n",
    "        criterion=\"ml\",\n",
    "        clustering_method=\"em\",\n",
    "        random_state=None,\n",
    "    ):\n",
    "        self.n_features_to_select = n_features_to_select  # 特徴量数\n",
    "        self.n_clusters = n_clusters  # クラスタ数\n",
    "        self.criterion = criterion  # 特徴量選択基準\n",
    "        self.clustering_method = clustering_method  # クラスタリング手法\n",
    "        self.random_state = random_state\n",
    "\n",
    "    def FSS(self, X, y, X_test):\n",
    "        X, y = check_X_y(X, y)\n",
    "        self.selected_features_ = []  # 選ばれた特徴量 #最初は特徴量１のみ\n",
    "        n_features = X.shape[1]  # 総特徴量数\n",
    "\n",
    "        current_features = []\n",
    "        temp_X = []\n",
    "        iter = 0\n",
    "\n",
    "        while len(current_features) < self.n_features_to_select:\n",
    "            iter += 1\n",
    "            best_feature = None\n",
    "            if iter == 1:\n",
    "                remaining_features = [i + 1 for i in range(n_features - 1)]\n",
    "\n",
    "            for feature in remaining_features:\n",
    "                temp_features = current_features + [feature]\n",
    "                if iter == 1 and temp_X == []:\n",
    "                    current_X = X[:, [0]]\n",
    "                else:\n",
    "                    current_X = temp_X\n",
    "                temp_X = X[:, temp_features]\n",
    "                normalized_score_current = self.calculate_normalized_score_current(\n",
    "                    current_X, temp_X, y\n",
    "                )\n",
    "                normalized_score_temp = self.calculate_normalized_score_temp(\n",
    "                    current_X, temp_X, y\n",
    "                )\n",
    "\n",
    "                if (\n",
    "                    iter == 1\n",
    "                    and temp_X == []\n",
    "                    and normalized_score_temp <= normalized_score_current\n",
    "                ):\n",
    "                    best_feature = 0\n",
    "                if normalized_score_temp > normalized_score_current:\n",
    "                    best_feature = feature\n",
    "\n",
    "            if iter == 1 and best_feature is not None:\n",
    "                current_features.append(best_feature)\n",
    "                remaining_features = [i for i in range(n_features)]\n",
    "                remaining_features.remove(best_feature)\n",
    "                self.selected_features_ = current_features\n",
    "            elif best_feature is not None:\n",
    "                current_features.append(best_feature)\n",
    "                remaining_features.remove(best_feature)\n",
    "                self.selected_features_ = current_features\n",
    "            else:\n",
    "                break\n",
    "\n",
    "        X_final_features = X[:, self.selected_features_]\n",
    "        if self.clustering_method == \"em\":\n",
    "            self.final_model_ = initialize_gmm_with_kmeans(\n",
    "                X_final_features,\n",
    "                n_clusters=self.n_clusters,\n",
    "                n_init=10,\n",
    "                random_state=self.random_state,\n",
    "            )\n",
    "        elif self.clustering_method == \"kmeans\":\n",
    "            self.final_model_ = kmeans_with_restarts(\n",
    "                X_final_features,\n",
    "                n_clusters=self.n_clusters,\n",
    "                n_init=10,\n",
    "                random_state=self.random_state,\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown clustering method: {self.clustering_method}\")\n",
    "\n",
    "        self.final_model_.fit(X_final_features)\n",
    "        self.final_cluster_assignments_ = self.final_model_.predict(\n",
    "            X_test[:, self.selected_features_]\n",
    "        )\n",
    "        return self\n",
    "\n",
    "    def calculate_normalized_score_current(self, current_X, temp_X, y):\n",
    "        X1 = current_X\n",
    "        X2 = temp_X\n",
    "        score_current = self.CRIT(X1, X1)\n",
    "        score_temp = self.CRIT(X2, X1)\n",
    "        score = score_current * score_temp\n",
    "        return score\n",
    "\n",
    "    def calculate_normalized_score_temp(self, current_X, temp_X, y):\n",
    "        X1 = current_X\n",
    "        X2 = temp_X\n",
    "        score_current = self.CRIT(X1, X2)\n",
    "        score_temp = self.CRIT(X2, X2)\n",
    "        score = score_current * score_temp\n",
    "        return score\n",
    "\n",
    "    def CRIT(self, X1, X2):  # X2空間上でしたクラスタリングの結果をX1空間上で評価\n",
    "        if self.clustering_method == \"em\":\n",
    "            em = initialize_gmm_with_kmeans(\n",
    "                X2,\n",
    "                n_clusters=self.n_clusters,\n",
    "                n_init=10,\n",
    "                random_state=self.random_state,\n",
    "            )\n",
    "            em.fit(X2)\n",
    "            labels = em.predict(X2)\n",
    "        if self.clustering_method == \"kmeans\":\n",
    "            kmeans = kmeans_with_restarts(\n",
    "                X2,\n",
    "                n_clusters=self.n_clusters,\n",
    "                n_init=10,\n",
    "                random_state=self.random_state,\n",
    "            )\n",
    "            kmeans.fit(X2)\n",
    "            labels = kmeans.predict(X2)\n",
    "\n",
    "        overall_cov_mean = np.mean(np.var(X1, axis=0))\n",
    "        identity_matrix = np.eye(X1.shape[1])\n",
    "        avoid_singular = overall_cov_mean * identity_matrix\n",
    "        cluster_num = len(np.unique(labels))\n",
    "\n",
    "        if self.criterion == \"ml\":\n",
    "            log_likelihood = 0.0\n",
    "        if self.criterion == \"tr\":\n",
    "            # 全体の平均ベクトル\n",
    "            overall_mean = np.mean(X1, axis=0)\n",
    "            # クラスター内分散行列（S_W）の計算\n",
    "            S_W = np.zeros((X1.shape[1], X1.shape[1]))\n",
    "            S_B = np.zeros((X1.shape[1], X1.shape[1]))\n",
    "\n",
    "        for cluster in range(cluster_num):\n",
    "            # クラスタに属するデータポイントを抽出\n",
    "            cluster_points = X1[labels == cluster]\n",
    "            # クラスタの平均ベクトル（μ）を計算\n",
    "            mean_vector = np.mean(cluster_points, axis=0)\n",
    "            # クラスタの共分散行列（Σ）を計算\n",
    "            cov_matrix = np.cov(cluster_points, rowvar=False)\n",
    "            if X1.shape[1] == 1:\n",
    "                cov_matrix = np.array([[cov_matrix]])\n",
    "            cov_matrix += avoid_singular\n",
    "\n",
    "            if self.criterion == \"ml\":\n",
    "                log_likelihood += np.sum(\n",
    "                    multivariate_normal.logpdf(\n",
    "                        cluster_points, mean=mean_vector, cov=cov_matrix\n",
    "                    )\n",
    "                )\n",
    "\n",
    "            if self.criterion == \"tr\":\n",
    "                S_W += cov_matrix * (cluster_points.shape[0] - 1)\n",
    "                n_k = cluster_points.shape[0]\n",
    "                mean_diff = (mean_vector - overall_mean).reshape(-1, 1)\n",
    "                S_B += n_k * np.dot(mean_diff, mean_diff.T)\n",
    "\n",
    "            if self.criterion == \"ml\":\n",
    "                score = log_likelihood\n",
    "            if self.criterion == \"tr\":\n",
    "                score = np.trace(np.linalg.inv(S_W).dot(S_B))\n",
    "\n",
    "        return score\n",
    "\n",
    "    def get_feature_index_out(self):\n",
    "        return np.array(self.selected_features_)\n",
    "\n",
    "    def get_final_cluster_assignments(self):\n",
    "        return self.final_cluster_assignments_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "\n",
    "clusters = 3\n",
    "n_features_to_select = 4  # 選択したい特徴量の数\n",
    "\n",
    "fssem_tr = Wrapper(\n",
    "    n_features_to_select=n_features_to_select,\n",
    "    n_clusters=clusters,\n",
    "    criterion=\"tr\",\n",
    "    clustering_method=\"em\",\n",
    "    random_state=0,\n",
    ")\n",
    "fssem_ml = Wrapper(\n",
    "    n_features_to_select=n_features_to_select,\n",
    "    n_clusters=clusters,\n",
    "    criterion=\"ml\",\n",
    "    clustering_method=\"em\",\n",
    "    random_state=0,\n",
    ")\n",
    "fsskmeans_tr = Wrapper(\n",
    "    n_features_to_select=n_features_to_select,\n",
    "    n_clusters=clusters,\n",
    "    criterion=\"tr\",\n",
    "    clustering_method=\"kmeans\",\n",
    "    random_state=0,\n",
    ")\n",
    "fsskmeans_ml = Wrapper(\n",
    "    n_features_to_select=n_features_to_select,\n",
    "    n_clusters=clusters,\n",
    "    criterion=\"ml\",\n",
    "    clustering_method=\"kmeans\",\n",
    "    random_state=0,\n",
    ")\n",
    "\n",
    "instance_dict = {\n",
    "    \"fssem_tr\": fssem_tr,\n",
    "    \"fssem_ml\": fssem_ml,\n",
    "    \"fsskmeans_tr\": fsskmeans_tr,\n",
    "    \"fsskmeans_ml\": fsskmeans_ml,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Wrapper.FSS() missing 1 required positional argument: 'X_test'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[68], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m cluster_size_dict \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, instance \u001b[38;5;129;01min\u001b[39;00m instance_dict\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m----> 5\u001b[0m     \u001b[43minstance\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFSS\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_scaled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m     selected_features_index \u001b[38;5;241m=\u001b[39m instance\u001b[38;5;241m.\u001b[39mget_feature_index_out()\n\u001b[0;32m      7\u001b[0m     selected_features_index_dict[name] \u001b[38;5;241m=\u001b[39m selected_features_index\n",
      "\u001b[1;31mTypeError\u001b[0m: Wrapper.FSS() missing 1 required positional argument: 'X_test'"
     ]
    }
   ],
   "source": [
    "# selected_features_index_dict = {}\n",
    "# cluster_label_dict = {}\n",
    "# cluster_size_dict = {}\n",
    "# for name, instance in instance_dict.items():\n",
    "#     instance.FSS(X_scaled, y)\n",
    "#     selected_features_index = instance.get_feature_index_out()\n",
    "#     selected_features_index_dict[name] = selected_features_index\n",
    "#     cluster_label = instance.get_final_cluster_assignments()\n",
    "#     cluster_label_dict[name] = cluster_label\n",
    "#     cluster_size = np.unique(cluster_label, return_counts=True)[1]\n",
    "#     cluster_size_dict[name] = cluster_size\n",
    "# print(selected_features_index_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "from sklearn.model_selection import KFold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HaruMomozu\\AppData\\Local\\Temp\\ipykernel_22464\\702686164.py:50: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  and temp_X == []\n",
      "C:\\Users\\HaruMomozu\\AppData\\Local\\Temp\\ipykernel_22464\\702686164.py:36: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if iter == 1 and temp_X == []:\n",
      "C:\\Users\\HaruMomozu\\AppData\\Local\\Temp\\ipykernel_22464\\702686164.py:50: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  and temp_X == []\n",
      "C:\\Users\\HaruMomozu\\AppData\\Local\\Temp\\ipykernel_22464\\702686164.py:36: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if iter == 1 and temp_X == []:\n",
      "C:\\Users\\HaruMomozu\\AppData\\Local\\Temp\\ipykernel_22464\\702686164.py:50: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  and temp_X == []\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [15, 1]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[70], line 29\u001b[0m\n\u001b[0;32m     27\u001b[0m labels \u001b[38;5;241m=\u001b[39m cluster_label_dict[name]\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# クラスタリング結果と実際のクラスラベルを比較\u001b[39;00m\n\u001b[1;32m---> 29\u001b[0m conf_matrix \u001b[38;5;241m=\u001b[39m \u001b[43mconfusion_matrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     30\u001b[0m row_ind, col_ind \u001b[38;5;241m=\u001b[39m linear_sum_assignment(\u001b[38;5;241m-\u001b[39mconf_matrix)\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# 誤分類率を計算\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\HaruMomozu\\Desktop\\momozu\\ABtesting\\.venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\HaruMomozu\\Desktop\\momozu\\ABtesting\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:342\u001b[0m, in \u001b[0;36mconfusion_matrix\u001b[1;34m(y_true, y_pred, labels, sample_weight, normalize)\u001b[0m\n\u001b[0;32m    247\u001b[0m \u001b[38;5;129m@validate_params\u001b[39m(\n\u001b[0;32m    248\u001b[0m     {\n\u001b[0;32m    249\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray-like\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    258\u001b[0m     y_true, y_pred, \u001b[38;5;241m*\u001b[39m, labels\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, normalize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    259\u001b[0m ):\n\u001b[0;32m    260\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute confusion matrix to evaluate the accuracy of a classification.\u001b[39;00m\n\u001b[0;32m    261\u001b[0m \n\u001b[0;32m    262\u001b[0m \u001b[38;5;124;03m    By definition a confusion matrix :math:`C` is such that :math:`C_{i, j}`\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    340\u001b[0m \u001b[38;5;124;03m    (0, 2, 1, 1)\u001b[39;00m\n\u001b[0;32m    341\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 342\u001b[0m     y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m \u001b[43m_check_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    343\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m y_type \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    344\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m is not supported\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m y_type)\n",
      "File \u001b[1;32mc:\\Users\\HaruMomozu\\Desktop\\momozu\\ABtesting\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:103\u001b[0m, in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Check that y_true and y_pred belong to the same classification task.\u001b[39;00m\n\u001b[0;32m     77\u001b[0m \n\u001b[0;32m     78\u001b[0m \u001b[38;5;124;03mThis converts multiclass or binary types to a common shape, and raises a\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    100\u001b[0m \u001b[38;5;124;03my_pred : array or indicator matrix\u001b[39;00m\n\u001b[0;32m    101\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    102\u001b[0m xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(y_true, y_pred)\n\u001b[1;32m--> 103\u001b[0m \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    104\u001b[0m type_true \u001b[38;5;241m=\u001b[39m type_of_target(y_true, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    105\u001b[0m type_pred \u001b[38;5;241m=\u001b[39m type_of_target(y_pred, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_pred\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\HaruMomozu\\Desktop\\momozu\\ABtesting\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:457\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    455\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[0;32m    456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 457\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    458\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    459\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[0;32m    460\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [15, 1]"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "selected_features_index_dict = {}\n",
    "cluster_label_dict = {}\n",
    "cluster_size_dict = {}\n",
    "errors = {}\n",
    "\n",
    "for name, _ in instance_dict.items():\n",
    "    selected_features_index_dict[name] = []\n",
    "    cluster_label_dict[name] = []\n",
    "    cluster_size_dict[name] = []\n",
    "    errors[name] = []\n",
    "\n",
    "for train_index, test_index in kf.split(X_scaled):\n",
    "    X_train, X_test = X_scaled[train_index], X_scaled[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    for name, instance in instance_dict.items():\n",
    "        instance.FSS(X_train, y_train, X_test)\n",
    "        selected_features_index = instance.get_feature_index_out()\n",
    "        selected_features_index_dict[name].append(selected_features_index)\n",
    "        cluster_label = instance.get_final_cluster_assignments()\n",
    "        cluster_label_dict[name].append(cluster_label)\n",
    "        cluster_size = np.unique(cluster_label, return_counts=True)[1]\n",
    "        cluster_size_dict[name].append(cluster_size)\n",
    "\n",
    "        labels = cluster_label_dict[name]\n",
    "        # クラスタリング結果と実際のクラスラベルを比較\n",
    "        conf_matrix = confusion_matrix(y_test, labels)\n",
    "        row_ind, col_ind = linear_sum_assignment(-conf_matrix)\n",
    "\n",
    "        # 誤分類率を計算\n",
    "        correct_predictions = conf_matrix[row_ind, col_ind].sum()\n",
    "        total_samples = len(y_test)\n",
    "        misclassification_rate = 1 - correct_predictions / total_samples\n",
    "\n",
    "        errors[name].append(misclassification_rate)\n",
    "\n",
    "for name, _ in instance_dict.items():\n",
    "    mean_error = np.mean(errors[name])\n",
    "    std_dev = np.std(errors[name])\n",
    "    std_error = std_dev / np.sqrt(len(errors[name]))\n",
    "\n",
    "    print(\n",
    "        f\"CV error for {name}:  {mean_error:.3f} +/- {std_error:.3f} (standard error)\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

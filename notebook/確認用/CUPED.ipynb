{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------\n",
    "### ライブラリのインポート＆その他の設定（Importing Libraries & Other Settings）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 基本的なライブラリ\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy.typing import NDArray\n",
    "from scipy import stats\n",
    "\n",
    "# Scikit-learn関連\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.utils.validation import check_X_y\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 抽象基底クラス (ABC)\n",
    "from abc import ABCMeta, abstractmethod\n",
    "\n",
    "# タイピングのサポート\n",
    "from typing import Optional\n",
    "\n",
    "\n",
    "# 可視化の設定\n",
    "import matplotlib.pyplot as plt\n",
    "import japanize_matplotlib\n",
    "import itertools\n",
    "\n",
    "plt.style.use(\"ggplot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------\n",
    "### 実験設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET = \"GMV\"  # \"GMV\"か\"BCR\"\n",
    "DATA = \"part\"  # \"all\" or \"part\"\n",
    "DATA_SIZE = 20000  # データサイズ(訓練データとテストデータあわせて）\n",
    "TEST_SIZE = 0.5  # テストデータの比率\n",
    "THRESHOLD = 2  # 外れ値除外の閾値\n",
    "\n",
    "N_TRIALS = 10000  # 試行回数（標本平均を求める回数）\n",
    "SAMPLE_SIZE = 100  # 標本サイズ\n",
    "RANDOM_STATE = 0  # 乱数シード"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------\n",
    "### データの前処理（Data Preprocessing）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 外れ値を除去する関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 外れ値の除去\n",
    "def remove_outliers_zscore(\n",
    "    data: pd.DataFrame, metric: str, threshold: float = 2\n",
    ") -> pd.DataFrame:\n",
    "    z_scores = np.abs(stats.zscore(data[metric]))\n",
    "    data = data[(z_scores < threshold)]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### メルカリデータ（df1：全部, df2：一部）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df1(all the data)\n",
    "df1 = pd.read_csv(\n",
    "    R\"C:\\Users\\HaruMomozu\\Documents\\aug_first_cpn_data_for_ab_test_sensibility_tsukuba.csv\"\n",
    ")\n",
    "\n",
    "features_list = [\n",
    "    \"hist_4_day_buy_num\",\n",
    "    \"hist_4_day_gmv\",\n",
    "    \"his_4_day_is_buy\",\n",
    "    \"hist_30_day_buy_days\",\n",
    "    \"hist_30_day_buy_num\",\n",
    "    \"hist_30_day_gmv\",\n",
    "    \"hist_30_day_buy_recency\",\n",
    "    \"hist_30_day_pay_days\",\n",
    "    \"hist_30_day_atpu\",\n",
    "    \"hist_30_day_gpv\",\n",
    "    \"hist_30_day_pay_recency\",\n",
    "    \"hist_30_day_list_days\",\n",
    "    \"hist_30_day_list_num\",\n",
    "    \"hist_30_day_list_recency\",\n",
    "    \"hist_30_day_like_count\",\n",
    "    \"hist_30_day_like_count_not_deleted\",\n",
    "    \"hist_30_day_like_recency\",\n",
    "]\n",
    "\n",
    "# df2(subset of the data)\n",
    "df2 = df1.iloc[:DATA_SIZE]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 外れ値除去と標準化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "外れ値除外前のデータ数（訓練+テスト）: 20000\n",
      "外れ値除外後のデータ数（訓練+テスト）: 19801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HaruMomozu\\AppData\\Local\\Temp\\ipykernel_1912\\3440415765.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"BCR\"] = np.where(df[\"GMV\"] > 0, 1, 0)\n"
     ]
    }
   ],
   "source": [
    "if DATA == \"all\":\n",
    "    df = df1\n",
    "if DATA == \"part\":\n",
    "    df = df2\n",
    "\n",
    "# 外れ値除去\n",
    "df = remove_outliers_zscore(data=df, metric=\"GMV\", threshold=THRESHOLD)\n",
    "\n",
    "df[\"BCR\"] = np.where(df[\"GMV\"] > 0, 1, 0)\n",
    "\n",
    "X_all = df[features_list]\n",
    "y_all = df[TARGET]\n",
    "\n",
    "# 行を詰める\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "print(\"外れ値除外前のデータ数（訓練+テスト）:\", DATA_SIZE)\n",
    "print(\"外れ値除外後のデータ数（訓練+テスト）:\", len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 訓練とテストに分割"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "訓練データのデータ数: 9900\n",
      "テストデータのデータ数: 9901\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_all, y_all, test_size=TEST_SIZE, random_state=0\n",
    ")\n",
    "\n",
    "print(\"訓練データのデータ数:\", len(X_train))\n",
    "print(\"テストデータのデータ数:\", len(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 目的変数と最も相関が高い共変量を選ぶ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GMVと最も相関の高い変数: hist_30_day_gmv, 相関係数: 0.37772488020585426\n"
     ]
    }
   ],
   "source": [
    "correlations = X_train.corrwith(y_train)\n",
    "\n",
    "# 最も相関が高い変数の選択\n",
    "most_correlated_var = correlations.abs().idxmax()  # 絶対値が最大の変数を取得\n",
    "max_correlation = correlations[most_correlated_var]\n",
    "\n",
    "print(\n",
    "    f\"{TARGET}と最も相関の高い変数: {most_correlated_var}, 相関係数: {max_correlation}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------\n",
    "### CUPED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CUPED(\n",
    "    X: pd.DataFrame,\n",
    "    y: pd.DataFrame,\n",
    "    covariate: str,\n",
    "    sample_size: int,\n",
    "    n_trials: int,\n",
    "    metric=\"GMV\",\n",
    "):\n",
    "    sample_means = np.zeros(n_trials)\n",
    "\n",
    "    # StandardScalerを使用して共変量をスケーリング\n",
    "    scaler = StandardScaler()\n",
    "    scaled_cov: NDArray = scaler.fit_transform(\n",
    "        X[covariate].values.reshape(-1, 1)\n",
    "    )  # X の covariate の列を NDarrayにしたものを標準化\n",
    "\n",
    "    # 共分散を使用してalphaを計算\n",
    "    alpha: NDArray = np.cov(y, scaled_cov[:, 0])[0, 1] / np.var(scaled_cov)\n",
    "    y_cuped = y - alpha * scaled_cov[:, 0]\n",
    "\n",
    "    for i in range(n_trials):\n",
    "        # y_cupedからランダムにサンプリング\n",
    "        sample = y_cuped.sample(n=sample_size, random_state=i)\n",
    "        sample_means[i] = sample.mean()\n",
    "\n",
    "    return np.var(sample_means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CUPED の分散\n",
    "cuped_std = CUPED(\n",
    "    X=X_test,\n",
    "    y=y_test,\n",
    "    covariate=most_correlated_var,\n",
    "    n_trials=N_TRIALS,\n",
    "    sample_size=SAMPLE_SIZE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.066076597762152\n",
      "208604.41171572442\n"
     ]
    }
   ],
   "source": [
    "# ランダムの分散\n",
    "np.random.seed(0)\n",
    "y_hats = []\n",
    "for random_state in range(N_TRIALS):\n",
    "    sample = np.random.choice(y_test, SAMPLE_SIZE, replace=False)\n",
    "    y_hat_random = sample.mean()\n",
    "    y_hats.append(y_hat_random)\n",
    "    random_std = np.array(y_hats).var()\n",
    "\n",
    "# CUPED の分散削減率\n",
    "reduction_rate = (1 - cuped_std / random_std) * 100\n",
    "print(reduction_rate)\n",
    "print(random_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
